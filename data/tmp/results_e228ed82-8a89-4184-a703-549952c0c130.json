[{"filename": "Candidate66_resume.docx", "text": "Candidate66\nPhone: 201-532-6397. Email: Candidate66@gmail.com\n__________________________________________________________________________________________________\nProfessional Summary\nOverall 10 years of experience as Sr. Technical Business System Analyst (Technical BSA) in Information Technology industry with focus on Data Analysis, Information & Data Management, Service-Oriented Architecture (SOA), Data Mapping & Data Modeling, Business Process Improvement, System Analysis & Design; expertise in implementation of IT projects using Project Management methodologies. Extensive experience in diversified industry sectors including Healthcare, Life Insurance, Personal & Commercial Insurance, Property & Casualty Insurance, Telecommunication, Retail & e-Commerce (Web Merchandising), Commercial & Investment Banking and Credit Card services.\nStrong skills in Data Warehouse Design using Star Schema roll out for the fact and dimension tables. Design of cubes, partitions and aggregations with excellent knowledge of Type 2 Data modeling.\nExpertise in application development with Full Lifecycle implementation of large Data Warehouse including Project Scope, requirements gathering, Star Schema Design, Snowflake Schema, Data Modeling and ODS.\nStrong experience in Data Analysis, Data Migration, Data Cleansing, Transformation, Integration, Data Import, and Data Export through the use of multiple ETL tools such as Informatica PowerCenter.\nStrong practical knowledge of analytical techniques and methodologies such as machine learning/supervised and unsupervised techniques, segmentation, mix and time series modeling, response modeling, lift modeling, experimental design, neural networks, data mining and optimization techniques. Expert knowledge of statistical analysis tools such as R-programming, MATLAB, Spark, SAS (Statistical Analysis System), R/Spark, Apache Hadoop and Cassandra.\nStrong background in applying statistical machine learning techniques to predictive modeling and experience with Machine Learning libraries (via R, H2O, Python, Spark, etc.). Proficiency in programming in Python, R-programming, SQL, JavaScript, Java/Scala/Ruby and shell scripting. Proficiency in consuming REST based API (with JSON payload). Fluency in big data platforms including Apache Hadoop, Apache MapReduce, Hive, Spark, and Pig. Familiarity with Cloud based HaaS/PaaS solutions such as AWS EMR (Amazon Web Services Elastic MapReduce), MS Azure. Strong understanding of data profiling and data cleansing techniques.\nThorough knowledge of eCommerce architecture; ATG framework its functional limitations and the platform features, application capabilities, etc. including industry wide terminologies like B2B, B2C, C2B, C2C with its eCommerce categories and strong knowledge of PCI DSS (Payment Card Industry Data Security Standards) standards.\nTechnical expertise in handling large-scale platform architecture, integrations, development using Java/J2EE Technologies. Experience on Oracle Commerce includes ATG Commerce, ATG Multisite, ATG Merchandising, and Content Management working in some of the key areas such as the Business Control Center (BCC), Profile Management, Shopping Cart, Checkout, Pricing, performance tuning, caching, infrastructure setup and Endeca.\u00a0\nStrong knowledge of application and systems performance improvement techniques, integration technologies, approaches and patterns, Web APIs / Web Service API calls (SoapUI / SOAP, RESTful API, SOA, XML, HTTP like GET / PUT / POST / DELETE, JSON, BitTorrent, Web 2.0, etc.). Strong knowledge of security aspects like risks and threats, authentication, authorization, certificates, encryption. Experience in utilizing frameworks and re-usable components.\nProficient in using Business Analysis tools such as MS Visio, Word, Excel (including Pivot tables, Macros and Vlookup), Rational Requiste Pro, ReqTrace Web, Caliber RM, Optimal Trace, ClearCase and ClearQuest.\nProficiency in elaborating the Use cases, writing Test cases and preparing Requirement Traceability Matrices (RTM).\nEducation: Master of Science in Engineering \u2013 New Jersey Institute of Technology (August 2008 to December 2009).\nCertification: Certified Data Scientist i.e. Data Science Professional (from John Hopkins University).\nTechnical Skills: Windows 95/98/NT/2000/XP/Vista/7, MS Visio, MS Access, MS Word, MS Excel, MS Project, Rational Rose Enterprise, IBM Rational Software Architect, Microsoft Project, Rational Requisite Pro, MS SQL Server 7.0/2000, PL/SQL, CSS (Cascading Style Sheet), OLTP & OLAP, Synon/2E, COBOL, IBM AS/400, CICS, Citrix, DB2, SAP ERP R/3 MMWM, SAP R/3 FICO, ERWIN Data Modeler 4.2/4.1/4.0, Business Objects XI r3, r2, r1, 6.5, 6.1, 5.x, 4.x, Crystal Reports XI, Informatica, HTML, Dream Weaver, MS FrontPage, IBM COGNOS (Report Studio, Query Studio, Framework Manager, Virtual View Manager, Business Insight Dashboard), Oracle BI Enterprise Edition (OBIEE), C#, C++, R Programming Language (Version 3.2.5), Minitab, XML, XSD, WSDL, X12, SAP PowerDesigner, SAP PowerBuilder, Analysis of Variance (ANOVA) and Experimental Design, Total Quality Management and Lean Six Sigma Manufacturing Methodologies, SAFe (Scaled Agile Framework) Practitioner, PMI\u2019s PMBOK guidelines & standards, TOGAF (The Open Group Architecture Framework), IIBA\u2019s BABOK guidelines & standards, Business Architecture Guild\u2019s BIZBOK (Business Architecture Body of Knowledge) standards & guidelines, Enterprise Architecture Body of Knowledge (EABOK), Enterprise Information Architecture (EIA) framework.\n\nProfessional Experience\nFidelity Investments (FMR) Smithfield, RI                               \t\t\t                                     Dec 2016 \u2013 Current\nDesignation: Principal Program Analyst / Technical Project Architect\nPrimary objective of the project was to address and resolve corporate Audit issue (Tier C) finding for the Enterprise Cybersecurity group on highly confidential Client Credentials (comprised of PII data) exposed into the server logs written by various Internal (employees within each business units, Broker \u2013 Dealer apps, 3rd party vendor apps) & External (customer / clients) Fidelity hosted applications, thereby applying log masking logic, data redaction techniques on these exposed keys within server logs physically located on multiple servers.\nDelivered elite level security solutions (for its Enterprise Cybersecurity business group) which essentially protects Fidelity and its customer's valuable information. Interacted with stakeholders, facilitated multiple fusion sessions and delivered the end results of work that provide the necessary requirements to the delivery team which thereby built and supported technology solutions.\nWorked as part of the Customer Protection Program, directly with Program and Project Managers as well as technology and business partners.\nWorked with tools such as Jira and Confluence to provide transparency of scope. Worked with our delivery team(s) including QA Data Services and engineering to ensure that we are meeting the needs of our stakeholders plus delivered solid, quality products to production. \nSupported Program and Project managers including providing input to/creation of strategy and execution plans and input to project status. Point person to escalate risks, change requests and participated in corrective actions (path to green).\nPerformed server logs analysis on Linux and Unix servers used by enterprise wide business units, thereby leveraged Splunk GUI tool to read and extrapolate pertinent meta data from these server logs. Used tools like Jira, ITEC PPMC, Confluence, etc. to track, monitor, delegate tasks / activities, operate different project aspects and functions.\nDerived insights out of ambiguity \u2013 understood, processed and interpreted complex data sets. Analyzed complex business data & identified patterns in the data using algorithms from statistics and machine learning. Developed and improved algorithms and methodologies to handle, browse, process and visualize structured and unstructured data.\nTranslated Business requirements, business rules and business criteria to system specifications and system requirements thereby preparing SRS (System Requirement Specifications) and PRS (Performance Requirement Specifications).\nEnvironment: MS Office Suite Package, MS Visio 2013 Pro, MS Excel Pivot Tables, MS Excel Functions & Formulas, MS Excel VLookUp, MS Excel Macros, Splunk Enterprise 6.5 (Splunk GUI Tool), Oracle 11g, IBM DB2, CyberArk EIAM (Enterprise Identity & Access Management), IBM InfoSphere Optim Data Privacy, ServiceNow, VMWare Tools, Oracle 11g Client 11.2.0.2 r01.02, Quest TOAD for Oracle, MS Access, Informatica Power Center, MS SQL Server, ITEC (IT Enablement Center) ALM (Application LifeCycle Management), Atlassian Confluence, ITEC (IT Enablement Center) Atlassian JIRA, Document Central, IBM DB2 Advanced Recovery Expert, IBM DB2 Merge BackUp, HP ITEC (IT Enablement Center) PPMC (Project & Portfolio Management Center).\n\nVerizon Wireless, Warren, NJ                               \t  \t\t\t\t\t\t    May 2016 \u2013 Dec 2016\nDesignation: Sr. Technical Business System Analyst / Technical Project Manager\nThe prime objective of the IoT (Internet Of Things), ReSale, M2M (Machine to Machine) portfolio was to utilize the core capabilities within MCS (Mobile Content Solutions) application suite module in order to web merchandise the non-tangible (like Licenses and Professional Services components within a cart) Items / SKUs through frontend Omni-channels; thereby foster & grow B2B (Business To Business), B2C (Business To Customer) business models from enterprise\u2019s strategic viewpoint and generate billing events at Account / Customer level from backend system application.\nAuthored, owned, managed and maintained 1Pagers to give brief overview of the products / services to be created and maintained in our MCS / SCM portal. Facilitated meeting sessions with Product Managers, Product Owners, Architectures and Analyst to hash out visio IoT (Internet of Things) Vendor flows, Order Fulfillment Flows and Order Processing Flows.\nPlanned, created, designed, managed and baselined draft high-level Project Scope, In-Scope & Out-Scope Functionalities, Draft SLAs (for 3rd party vendors / partners), Baseline Project Timelines & Gantt Chart at project implementation level with external 3rd party vendors / partners (in order to accomplish System Integration Testing [SIT] milestone) system application.\nDefined, designed and elicited core business objectives in order to deliver qualitative product, program and project with optimum utilization and the most efficient use of enterprise resources.\nManaged project charter, project plans, scope statement, project execution, risk mitigation, contingency plan and achievement of project and program objectives. Managed SIT & UAT test activities by ensuring defects are logged accurately in JIRA and issues resolved appropriately.\nCreated, aligned and logged EPICS, User Stories / Features, Tasks (Development, Infrastructure & QA Tasks), Bugs, Defects, BRs (Build Requests), DRs (Deployment Requests), Issues, etc. in JIRA tool.\nStrong knowledge of Unix commands and running those Unix commands in various boxes to validate server logs.\nEffectively and lucidly communicated project risks, issues (especially launch gating), dependencies, progress status, launches, concerns and retrospectives in structured RAID template designed and choreographed by me.\nEnvironment: Activiti BPM, XML Spy, RestFUL API, SoapUI, HP Quality Center ALM (Application Lifecycle Management) 12.20 & 12.01, Quest Toad For Oracle 12.0 (64bit), Programmer\u2019s Notepad, PuTTY.exe, JIRA, CA\u2019s Clarity PPM, Cloudsite SharePoint, Confluence document repository, APEX Search Client RealTime application, DB2 AppDevClient 9.7, MS Office Project Standard 2007, MS Office Standard 2007, MS Office Visio Standard, Open Source XML tools, Oracle Client 11g R2 11.2.0.1.0, Techsmith\u2019s SnagIT Editor 12, SQL Developer 4.1.3.\n\nChubb Insurance / Chubb Group of Insurance Companies, Whitehouse Station, NJ                            July 2015 \u2013 May 2016\nDesignation: Sr. Technical Business System Analyst / Project Architect\nThe purpose of the Client Integration initiative is to be able to view and manage PRS\u2019 business at the client / household / account level in an integrated fashion so that we can make better and faster underwriting decisions, more effectively market and communicate with existing and potential clients, price across clients and deliver better customer service. Integrate PLS & ORCA into the Chubb Client MDM/UI in order to provide an integrated household policy portfolio view across key Chubb Policy Admin Systems for Personal Lines segment, along with the other legacy Chubb\u2019s disparate policy admin systems like MasterPiece, CAAS & Yacht.\nCreated and documented roadmap for meetings with ACE. Baselined documents used for source to target mapping. Understanding CHUBB's system and applications i.e. Target system for CLIENT INT project.\nDesigned, developed and maintained consistency of the Pre-landing and Landing tables \u201cGeneric Landing Layout\u201d file / sheet that the core execution team leveraged for Source To Target Mapping sessions. \nCreated and documented High Level Data Movement and Data Flow diagrams, High Level & Detailed Conceptual Architecture diagrams using BPMN (Business Process Model and Notation) standards encapsulating every system components within visio flows. Conducted thorough analysis on CPI data models for Subject Of Insurance, Policy, Policy Term, Business Party schemas.\nConfirmed on the mapping performed within \u201cORCA Policy Status Mapping\u201d sheet for \u201cTransaction Status\u201d type and \u201cContract Status\u201d type. Confirmed the data points in \u201cMatch Columns\u201d column for the \u201cMatch Rules\u201d from \u201cClient INT ORCA Match Rules\u201d sheet. Gave an overview on \u201cSystem Triggers\u201d and introduced team on triggers. \nIntegrated Survivorship Rules for 6 Personal Lines Systems. Overview of \u201cSurvivorship Rules\u201d (like \u201cWhat is Survivorship and what does it mean to MDM process & Client UI application?\u201d) and introduce team to \u201cSurvivorship / Survival Rules Matrix\u201d sheet.\nWas responsible for identifying and documenting business rules and creating detailed Use Cases, Use Case models, Use Case diagrams and Object Oriented Analysis and Designs (OOAD) using UML (Unified Modeling Language).\nPrepared ER Diagrams, documented Data Dictionary, identified database schemas, its data elements/fields, and studied their nomenclatures from the identified columns, for phased deliverables. \nEnvironment: Informatica Data Director (IDD), Informatica Analyzer, DB2, Informatica Power Center, MDM, Oracle 11g, Information Builder\u2019s WebFocus 8, IBM Cognos Report Studio 10, IBM Lotus Notes, CICS, Cobol, Oracle SQL Server, MS Visio, MS Office Suite, MasterPiece, Guidewire policy admin system, CAAS, Yacht, PLS, ORCA, DRC, SharePoint.\n\nBed Bath and Beyond, Union, NJ                                          \t\t\t\t\t                   July 2014 \u2013 July 2015\nDesignation: Lead Technical Business System Analyst / Technical Product Manager\nPrime focus of the EXIM/Universal Cart was to have the ability to export products/items from BBBY\u2019s online channels (both desktop & mobile applications) to 3rd party vendor sites that offer personalization and/or customization services (like monogramming, etching, sublimation/printing etc.) not currently available on BBBY\u2019s sites/concepts (concepts like BBBY-US, BBBY-Canada, BuyBuyBaby, Christmas Tree Shops, etc.).\nPerformed requirements gathering & analysis by actively soliciting, examining, investigating and negotiating customer requirements with business directors and Product Development Managers, while leading the technical requirements analysis and driving the system design and construction. \nPerformed extensive SKU to Product relationship mapping at UPC level, SKU/item level, Product level, Collection & Accessories level, etc. Thereby understood cardinality between SSWPs (Single SKU Web Products) and MSWPs (Multi SKU Web Products) and process by which they are \u201cWeb Enabled\u201d and \u201cWeb Disabled\u201d for \u201cDigital Merchandising\u201d.\nConducted numerous impact analysis sessions, thereby analyzing the behavior of multiple features & functionalities on different web pages like PLP (Product List Page \u2013 Grid View & List View), PDP (Product Detail Page), Quick View, Collection & Accessories, Your Cart page, Single Shipping & Multi Shipping Location, Order Confirmation, Order Preview, Order History, Track Order, etc. and on the user CTA (Call to Action) button (buttons like Add to Cart, Add to Registry, Save for Later, Find in Store).\nCreated / Documented, managed, controlled and delivered user stories, features and functionalities in form of Story or Functional Requirements (i.e. formal FRD) within the CCM & RM tools respectively. Updated the tools with appropriate COS (Condition of Satisfaction) / Acceptance Criteria, Story Title, Card, Conversation, Assumptions etc. by following standardized Agile SCRUM methodology/process.\nAlso created / documented, managed, controlled and delivered Epic, Features, Story, Tasks, Spikes by breaking these out appropriately and then tie them back to the concerned Feature and Story within the RM (Requirements Management) tool.\nCollaborated with the development team to enforce the implementation of requirements throughout the entire coding cycle and managed change request using Rational Clear Quest.\nEnvironment: IBM\u2019s Rational Tools, IBM Requirement Management Tool, IBM Change & Configuration Management Tool, RMTrack \u2013 Defect Tracking, JIRA, ATG eCommerce Platform, TIBCO, Riversand\u2019s PIM (Product Information Management), Tableau, QlikView, STIBO\u2019s PDM (Product Data Master), Web2.0, Oracle SQL Server Developer, Microstrategy, Oracle Endeca, UNIX, Java, .Net.\n\nMaryland Department of Health & Mental Hygiene / CSC - CNSI, Baltimore, MD                                  Jan 2013 \u2013 July 2014\nDesignation: Sr. Technical Business System Analyst / BI Reporting Lead\nThe prime objective of the project is to replace the current MMIS Claims processing system for DHMH, with a web-based Service Oriented Solution consistent with MITA 2.0 (Medicaid Information Technology Architecture) guidelines that has online web capabilities for all Users including Providers and Recipients/Beneficiaries. The system\u2019s User Interface intent was to provide the capability for online data entry for Provider Enrollment applications; track and automate Workflow Management of the process; and online verification of Provider Enrollment status.\nReviewed, analyzed, evaluated business processes and associated IT application requirements. Analyzed business workflow and system needs for conversions and migrations; performed data mapping and data conversions.\nIdentified specifications for billing and accounts receivable requirements, performed gap analysis & presented information to technical team to identify system requirements. Worked extensively with developing business rules engine enabling the business rules such as referral, prior authorization, eligibility, claims processing and billing essential.\nInvolved in implementation of HIPAA EDI Transactions (835, 837). Facilitated Electronic Data Interchange (EDI). Performed GAP Analysis for HIPAA 4010 and 5010 transactions. Used EDI tools to verify mapping to X12 format. Recommended changes for system design, methods, procedures, policies and workflows affecting Medicare / Medicaid claims processing in compliance with government compliant processes like HIPAA / EDI formats and accredited standards ANSI. Analyzed HIPAA EDI transactions in X12 responses and of 837, 835, 277CA and 999 and looked for defects.\nRecommended changes for system design, methods, procedures, policies and workflows affecting Medicare/Medicaid claims processing in compliance with government compliant processes like HIPAA/ EDI formats and accredited standards ANSI.\nConducted detail oriented analysis on the current \u201cAS-IS\u201d Maryland MMIS legacy system and driving iterative GAP analysis sessions for the same to propose the effective target \u201cTO-BE\u201d MMIS system.\nDesigned Dashboards/Reports using the Oracle Business Intelligence Analytics platform for requirement analysis and data analytics. Enhanced performance of Reports / Dashboards by implementing the Aggregate tables, Materialized Views, Table partitions, re-building of indexes and managing Cache etc.\nResponsible for processing Medicaid claims in a workflow environment. Accurately interpreted benefit & policy provisions applicable to Medicaid enrollees. Reviewed & resolved claim edits using multiple systems, processes and procedures.\nEnvironment: MMIS / CMS Regulations, HIPAA Privacy, Wire Framing, UML, SCRUM, eCAMS & ProviderOne (CNSI owned & developed Claims Administration System), iLotus Notes, IBM COGNOS 10 Report Studio, Oracle Financials, JIRA (Defect Tracking Tool), ReqTrace Web 2.1, Oracle SQL Developer, J2EE, .NET, Oracle ODBC, Oracle BI Enterprise Edition 11g, MS Office Suite, MS Excel, MS Project, SharePoint, Service Oriented Architecture (SOA), RUP (For MMIS Development), Informatica PowerCenter, Enterprise Architect 10 UML (SPARX System\u2019s EA Visual Modeling Platform).\n\nMedco Health Solutions Inc. / Express Scripts Inc., Franklin Lakes, NJ                                                       Oct 2011 \u2013 Jan 2013\nDesignation: Sr. Technical Business System Analyst\nThe purpose of the project was to report the back-end Teradata IW databases utilizing the front-end Cognos BI reporting tool for the Medicare Part D claims Adjustments & Reconciliation and Operations Workbook business process. This project involved creation of a Medicare, Medicaid Solutions (MMMS) dashboard that included views from various channels, operational divisions and products within the Medicare organization.\nGathered all the Reporting Requirements and functional requirements through JAD sessions, formal interviews and brain storming sessions from the Business Owners and stakeholders based on the project scope and documented it in form of FRDs and Use-Cases in CaliberRM / Optimal Trace.\nConducted JAD sessions with different Business Users to develop new policies and procedures for the Service Catalogue, Charge Capture and Service Worklist /Charge Router, Hospital billing, coding, special coding requirements for Medco Health / Express Scripts and Claim processing.\nInvolved in analysis, design, and implementation of the following systems \u2013 Control Management Reporting and Security Systems: generation of daily, weekly, and monthly reports of hospital patients' activity. Medical Billing & Collection Systems: generation of daily billing activity based on patient records & establishment of collection protocols. Accounting Systems: Financial Statement generation and analysis according to government standards and protocols.\nWorked on EDI transactions: X12, 835, and 837 P.I to identify key data set elements for designated record set. Interacted with Claims, Payments and Enrollment hence analyzing and documenting related business processes.\nInvolved in the System Analysis, Design and Development of the project. Integral part of end-to-end implementation of IW Reporting from capturing reporting requirements, Relational data modeling in Cognos, Metadata analysis, mock-up template designing and BI reporting system.\nDisplayed in depth knowledge of Medicare/Medicaid Claims processes from Admin/Provider/Payer side which were later part of the training program to vendors. Worked on improvement of Claims Reimbursement User Interface for a better experience and incorporate changes as per HIPAA guidelines using the gap analysis.\nIdentified the functional as well as technical needs of the department and accordingly engaged as liaison between the Upper Management and IT Team to develop Cognos based BI Reports, applications and softwares.\nAssisted in development of the reports using Cognos Report Studio and Framework Manager. Developed Forms, Reports and Queries using MS Access and Excel (including Pivot tables, Vlookup and Macros).\nEnvironment: SCRUM, RUP, SharePoint, Synon/2E, COBOL, IBM AS/400, IBM Cognos 10 (Report Studio, Query Studio, Framework Manager, Virtual View Manager, Business Insight Dashboard), UNIX, Microsoft SQL Server 2008, T-SQL, MS SQL Server, Teradata IW, BRIO Query Intelligence, MS Office Suite, MS Project, MS Visio, ERWIN, OiM (Oracle Identity Manager), ORACLE SQL Server Developer, Teradata, DB2, Informatica Powercenter, CA ERwin Data Modeler, Oracle BI Enterprise Edition 10g, PL/SQL, CAs ALL Fusion Harvest, HP Quality Center, EDI, XML, .CSV (Comma Delimited), Rational Clear Quest, Anchor DW, Foundation14 (F14), CaliberRM 64Bit Production, Optimal Trace, MagicDraw UML.\n\nCVS Caremark, Richardson, TX                                                                                   \t\t\t      Jan 2010 \u2013 Oct 2011\nDesignation: Sr. Technical Business Analyst\nThe primary goal of the project is to extract common services such as Eligibility, Formulary, Drug Maintenance, etc. out of the disparate systems and host them independently to facilitate economy of operations, isolation of common business services from core adjudication transaction processing and externalize the data in a way that can be consumed by other external applications within the Organization. This will enable common services, tools and interfaces that can improve client experience and drive consistency regardless of which adjudication engine is used.\nGathered, analyzed, documented business and technical requirements from both formal and informal sessions and validate the needs of the business stakeholders, thereby drafting the Technical Design Document (TDD) and System Specification Document (SSD).\nDesigned and developed Use Cases and Use Case scenarios, Activity Diagrams, Sequence Diagrams, High Level and Low Level Process Flow Diagrams, OOAD using UML and Business Process Modeling. Understood client\u2019s business needs related to operational payer departments (i.e. claims, enrollment, billing, etc.).\nProfiled data in the sources prior to defining the data cleaning rules. Perform small enhancements (data cleansing/data quality). Worked on various Professional billing and Hospital billing products.\nDesigned and implemented unique platform, which collected and synchronized information of each person all in one place, including medical claims, lab results, self reported data and other relevant information and also in an efficient and effective manner.\nResponsible for preparing Business Requirement Document (BRD), Functional Requirement Document (FRD) and then translating into functional specifications and test plans. Closely coordinated with both business users and developers for arriving at a mutually acceptable solution.\nDeveloped project definitions, project scope, cost/benefit and risk analysis, work plans, daily and weekly progress reports, and presentations. Created and tested scripts for the premium calculations and claim limits and deductible.\nReviewed the use cases, functions and features list, map the requirements to design, and update the Requirements Traceability Matrix (RTM). Created various reports such as billing payment reports, Billing Grouping Payment and discount reports.\nResponsible to give the payers the clear vision of claim life cycle from submission to CVS Caremark through payer adjunction. Designed & implemented a web based claims processing system & management application to administer and process health insurance claims automatically. It connected the organization to largest all-payer network of commercial & government health plans nationwide to provide wealth of real-time patient benefit information.\nCreated source table definitions in the Data Stage Repository by studying the data sources by importing the data from Mainframe.\nWrote PL/SQL statement and stored procedures in Oracle for extracting as well as writing data. Created and executed claims, enrollment and/or billing test scenarios, including defect tracking.\nEnvironment: RUP, SharePoint, Synon/2E, COBOL, IBM AS/400, CICS, Citrix, Cognos 8, DB2, SAP R/3 FICO, Microsoft SQL Server 2008, T-SQL, SSIS, SSRS, SSAS, MS Excel, MS Word, MS Access, MS Project, MS Visio, ERWIN, Data Stage, OiM (Oracle Identity Manager), Oracle, PL/SQL, PC Media, Oracle BI Enterprise Edition 10g, CAs ALL Fusion Harvest, EDIFECS, HP Quality Center, Velocedi/Claredi, EDI, XML, DIAMOND, COSMOS, FACETS, LOGISTICARE, Rational Rose, Bugzilla, Snagit, Adobe Acrobat Professional, HP Quality Center.\n\nDelta Technologies                                                                                             \t\t\t     July 2006 \u2013 Aug 2008\nDesignation: Lead Technical Business Analyst                                                                                                                   \nThe project was to report corporate data warehouse for online trading system. The reporting system was to capture the KPI such as the trade volumes, number of trades, on the counter trades, and exchange trades, broker dealer trades, trade fees with respect to dimensions such as customer\u2019s location, security type, exchange traded Fees payables, etc.\nGathered the business requirements from the managers through JAD sessions, formal interviews and surveys and worked extensively with the users and with different levels of management to identify requirements, business events to develop functional specifications.\nAnalyzed the AS-IS and TO-BE processes to understand the key findings, the short term considerations, the long term considerations and its benefits.\nOwned the entire reporting process. Interacted with the ETL team, developer(s), management, and account holders to get the requirements, document them, design templates, and write specifications.\nIdentified data elements from the source systems, performed data analysis to come up with data cleansing and integration rules for the ETL process using Informatica.\nAnalyzed research on operational procedures and methods and recommended changes for improvement, with an emphasis on automation and efficiency.\nPerformed analysis and design of applications using OOAD techniques, UML and Design Patterns.\nGathered all the requirements from the stakeholders based on the project scope and documented it in RequisitePro.\nConducted interviews with various business users and Subject Matter Experts (SMEs) to collect Requirements and business process information, using Requisite Pro exercised all the different types of views in Requisite Pro Attribute matrix.\nInvolved in the testing phase right from the Unit testing to the User Acceptance testing.\nDocumented existing and proposed process flow, analyzed current and target system, and conducted GAP analysis from the reporting requirements to the existing data in ODS.\nEnvironment: RUP, Requisite Pro, Data Stage, Rational Tools, Cognos 8, MS Project, MS Word, MS Excel, MS Visio, MS Office Suite, Rational Rose, Windows Vista, ERWIN, MS SQL Server, PL/SQL, SSIS, SSRS, SSAS, Crystal Reports XI.", "years_experience": 10, "score": 0.22074462426954886, "path": "C:\\Users\\admin\\resume\\AI-Resume-Ranker\\data\\uploads\\Candidate66_resume.docx"}, {"filename": "Candidate23_Hadoop_developer.docx", "text": "Candidate23\nSr. Hadoop Developer\nPhone: +1(224)-706-0020 \u00a0\u00a0\nEmail: candidate23.dbj@gmail.com \n------------------------------------------------------------------------------------------------------------------------------------------\nPROFESSIONAL SUMMARY:\nOver 8+ years of experience including 4 years of Big Data Ecosystem related technologies with full project development, implementation and deployment.\nStrong Experience working with various Hadoop ecosystem components like, Map Reduce, HDFS, Hive, Sqoop, Pig, Flume, and Oozie.\nStrong Knowledge on Architecture of Distributed systems and Parallel processing frameworks. \nIn-depth understanding of MapReduce Framework and Spark execution model.\nWorked extensively on fine-tuning long running Spark Applications to utilize better parallelism and executor memory for more caching.\nStrong experience working with both batch and real-time processing using Spark framework.\nExpertise in developing production ready Spark applications utilizing Spark-Core, Data frames, Spark-SQL, Spark-ML and Spark-Streaming API's.\nHands on experience in installing, configuring and deploying Hadoop distributions in cloud environments (Amazon Web Services).\nExpertise in developing production ready Spark applications utilizing Spark-Core, Data frames, Spark-SQL, Spark-ML and Spark-Streaming API's.\nWorked on building real time data workflows using Kafka, Spark streaming and HBase.\u00a0\nWorked extensively on Hive for building complex data analytical applications.\nVery good understanding of Partitions, bucketing concepts in Hive and designed both Managed and External tables in Hive to optimize performance.\nUsed custom serDes like Regex SerDe, JSON SerDe, CSV SerDe etc., in hive to handle multiple formats of data. \nHaving knowledge in Apache Ambari platform for securing, managing and monitoring Hadoop clusters.\nExperienced in Cluster coordination services through zookeeper.\nStrong experience using different columnar file formats like Avro, RCFile, ORC and Parquet formats.\nWorked with Sqoop to move (import/export) data from a relational database into Hadoop.\nExperience working with Hadoop clusters using Cloudera, Amazon EMR and Hortonworks distributions.\nExtensive experience in performing ETL on structured, semi-structured data using Pig Latin Scripts.\nDesigned and implemented Hive and Pig UDF's using Java for evaluation, filtering, loading and storing of data.\nExperienced in job workflow scheduling and monitoring tools like Oozie.\nWell versed with UNIX and Linux command line and shell script.\nAdequate knowledge and working experience with agile methodology.\n\nTECHNICAL SKILLS:\n\n\nEDUCATION:\nBachelor of Technology in Computer Science Engineering \n\nWORK EXPERIENCE:\n\nCigna \u2013 Bloomfield, Connecticut                                                             \t\t       Jul\u201917 \u2013 Present \nRole: Hadoop/Spark Developer \n\nResponsibilities:\nDeveloped Spark applications using Scala utilizing Data frames and Spark SQL API for faster processing of data.\nDeveloped highly optimized Spark applications to perform various data cleansing, validation, transformation and summarization activities according to the requirement\nData pipeline consists Spark, Hive and Sqoop and custom built Input Adapters to ingest, transform and analyze operational data.\nDeveloped Spark jobs and Hive Jobs to summarize and transform data.\nUsed Spark for interactive queries, processing of streaming data and integration with NoSQL database HBase, Cassandra for interactive access patterns.\nInvolved in converting Hive queries into Spark transformations using Spark Data Frames in Scala.\nAutomated creation and termination of AWS EMR clusters using AWS, java sdk.\nBuilt real time data pipelines by developing Kafka producers and spark streaming applications for consuming.\nIngested syslog messages to Kafka.\nWorked on Apache Airflow to schedule single and sometimes complex chains of tasks that depend on each other on regular intervals.\nHandled importing data from relational databases into HDFS using Sqoop and performing transformations using Hive and Spark.\nHaving knowledge in Apache Ambari platform for securing, managing and monitoring Hadoop clusters.\nExported the processed data to the relational databases using Sqoop, to further visualize and generate reports for the BI team.\nExperienced in cluster coordination services through Zookeeper.\nInstalled, tested and deployed monitoring solutions with Splunk services.\nUsed Hive to analyze the partitioned and bucketed data and computed various metrics for reporting.\nDeveloped Hive scripts in Hive QL to de-normalize and aggregate the data.\nScheduled and executed workflows in Oozie to run various jobs.\nDesigning & creating ETL jobs through Talend to load huge volumes of data into Cassandra, Hadoop Ecosystem and relational databases.\n\nEnvironment: Hadoop, Spark, Hive, Java, Scala, Maven, Impala, Oozie, Oracle, Ambari, GitHub, Tableau, Unix, Hortonworks, Apache Airflow Kafka, Zookeeper, Sqoop, Cassandra, Talend, Splunk, HBase.\n\nQualcomm -- San Diego, CA                                                                   \t\t          Dec\u201916 \u2013 Jun\u201917                                                                                            \nRole: Hadoop/Spark Developer\n\nResponsibilities:\n\nPart of Big Data Center of Excellence (CoE), responsible for designing and building enterprise data analytics platform.\nWorked with respective business units in understanding the scope of the analytics requirements.\nPerformed core ETL transformations in Spark.\nAutomated data pipelines which involve data ingestion, data cleansing, data preparation and data analytics.\nCreated end to end Spark applications using Scala to perform various data cleansing, validation, transformation and summarization activities on user behavioral data.\nDeveloped end-to-end data pipeline using FTP Adaptor, Spark, Hive and Impala.\nImplemented Spark utilizing Spark-SQL heavily for faster development, and processing of data.\u00a0 \nExploring with Spark for improving the performance and optimization of the existing jobs in Hadoop using Spark-SQL, Data Frame running in Yarn mode.\nHandled importing other enterprise data from different data sources into HDFS using Sqoop and performing transformations using Hive, Map Reduce and then loading data into HBase tables.\nCollecting and aggregating large amounts of log data using Flume and staging data in HDFS for further analysis\nWrapper developed in Python for instantiating multithreaded application and running with other applications.\nAnalyzed the data by performing Hive queries (Hive QL) and running Pig scripts (Pig Latin) to study customer behavior.\nData warehousing, experience in design, development and testing, implementation and support of enterprise data warehouse.\nUsed Hive to analyze the partitioned and bucketed data and compute various metrics for reporting.\nCreated components like Hive UDFs for missing functionality in HIVE for analytics.\nWorked on various performance optimizations like using distributed cache for small datasets, Partition,\u00a0Bucketing in Hive and Map Side joins.\nCreated Oozie workflows and coordinators to automate data pipelines daily, weekly and monthly.\nAutomated creation and termination of AWS EMR clusters using AWS, java sdk.\n\nEnvironment: AWS EMR, Hadoop, Spark, Hive, Sqoop, HBase, UNIX, Talend, Pig, Linux, Java, Scala, Python, Ambari, Zookeeper.\nHortonworks\n\nMcKesson - Alpharetta, GA                                                                   \t\t        Dec\u201915 \u2013 Nov\u201916\nHadoop/Spark Developer\n\nResponsibilities:\n\nDeveloped multithreaded Java based Input adaptors for ingesting click stream data from external sources like ftp server and S3 buckets on daily basis.\nCreated various spark applications using Scala to perform various enrichment of these click stream data combined with enterprise data of the users.\nImplemented batch processing of jobs using Spark Scala API.\nDeveloped Sqoop scripts to import/export data from Oracle to HDFS and into Hive tables.\u00a0\nStored the data in columnar formats using Hive.\nInvolved building and managing NoSQL Database models using HBase.\nWorked in Spark to read the data from Hive and write it to Hbase.\nOptimized the Hive tables using optimization techniques like partitions and bucketing to provide better performance with Hive QL queries.\u00a0\nWorked with multiple file formats like Avro, Sequence, Parquet and Orc.\nConverted existing MapReduce programs to Spark Applications for handling semi structured data like JSON files, Apache Log files, and other custom log data.\nLoaded the final processed data to HBase tables to allow downstream application team to build rich and data driven applications.\nWorked with a team to improve the performance and optimization of the existing algorithms in Hadoop using Spark, Spark -SQL, Data Frame.\nImplemented business logic in Hive and written UDF\u2019s to process the data for analysis.\nUsed Oozie to define a workflow to coordinate the execution of Spark, Hive and Sqoop jobs.\nAddressing the issues occurring due to the huge volume of data and transitions.\nDesigned, documented operational problems by following standards and procedures using JIRA. \n\nEnvironment: Java, Hadoop 2.1.0, Map Reduce2, Spark, Unix, Pig 0.12.0, Hive 0.13.0, Linux, Sqoop 1.4.2, Flume 1.3.1, Eclipse, AWS EC2, and Cloudera CDH 4.  \n\nAmerican Home Shield - Memphis, TN                                                \t\t         Dec\u201914 \u2013 Nov\u201915\nRole: Hadoop Developer\n\nResponsibilities:\n\nMigrated the needed data from MySQL into HDFS using Sqoop and importing various formats of flat files in to HDFS.\nMainly worked on Hive queries to categorize data of different claims.\nInvolved in loading data from LINUX file system to HDFS\nWritten customized Hive UDFs in Java where the functionality is too complex.\nImplemented Partitioning, Dynamic Partitions, Buckets in HIVE.\nDesigning and creating Hive external tables using shared meta-store instead of derby with partitioning, dynamic partitioning and buckets.\nGenerate final reporting data using Tableau for testing by connecting to the corresponding Hive tables using Hive ODBC connector.\nResponsible to manage the test data coming from different sources\nReviewing peer table creation in Hive, data loading and queries.\nWeekly meetings with technical collaborators and active participation in code review sessions with senior and junior developers.\nMonitored System health and logs and respond accordingly to any warning or failure conditions.\nGained experience in managing and reviewing Hadoop log files.\nInvolved in scheduling Oozie workflow engine to run multiple Hive and pig jobs\nInvolved unit testing, interface testing, system testing and user acceptance testing of the workflow tool.\nCreated and maintained Technical documentation for launching Hadoop Clusters and for executing Hive queries and Pig Scripts\n\nEnvironment: Apache Hadoop, HDFS, Hive, Map Reduce, Core Java, Pig, Sqoop, Cloudera CDH4, Oracle, MySQL.\n\nProtective Life - Edina, MN                                                                      \t\t         Oct\u201913 - Nov\u201914     \nRole: Java Developer\n\nResponsibilities:\n\nImplemented a Web based Application using Servlets, JSP, spring, JDBC, XML.\u00a0\nInvolved in writing Spring Configuration XML file that contains declarations and other   dependent objects declarations.\u00a0\nUsed hibernate to connect to Database to create the DAO layer.\u00a0\nDeveloped Application Framework using Model-View-Controller using the technology Spring.\u00a0\nUsed HTML, XHTML, XML, XSLT, XPATH, JSP and Tag Libraries to develop view pages\u00a0\nMultilayer Applications construction using Open JPA, HTML5, Spring MVC.\u00a0\nAnnotated Spring Architecture (Spring Beans)\u00a0\nImplemented UNIX shell scripts to migrate various data files to S&P ratings repository\u00a0\nImplemented smooth pagination capability using\u00a0JSP to remove existing pagination utility\u00a0\nWorked on Geo API to provide geological access capability to S&P.com site.\u00a0\nInvolved in Agile process to streamline development process with iterative development.\u00a0\nCode reviews and Managing the CVS Repository.\u00a0\nPrepare builds for DEV and UAT environments.\u00a0\nParticipating in the regular team meetings sprint planning meetings, user story review meetings etc.\u00a0\nInvolved in preparing High & low level design docs with UML diagrams using Microsoft VISIO tool.\u00a0\n\nEnvironment: JDK 1.5, XML, HTML, XHTML, JSP, Spring, DAO, Oracle Express edition, Apache ANT, CVS, Junit, UNIX, Log4J, CSS Style Sheets, Apache Tomcat, J2EE, Maven 3\n\nAccenture \u2013 USA\t\t       Oct\u201911\u2013 Sep\u201913\nRole: Java Developer\n\nResponsibilities:\n\nInvolved in Requirements analysis, design, and development and testing.\nInvolved in setting up the different roles & maintained authentication to the application.\nDesigned, deployed and tested Multi-tier application using the Java technologies.\nInvolved in front end development using JSP, HTML & CSS.\nImplemented the Application using Servlets\nDeployed the application on Oracle Web logic server\nImplemented Multithreading concepts in java classes to avoid deadlocking.\nUsed MySQL database to store data and execute SQL queries on the backend.\nPrepared and Maintained test environment.\nTested the application before going live to production.\nDocumented and communicated test result to the team lead on daily basis.\nInvolved in weekly meeting with team leads and manager to discuss the issues and status of the projects.\n\nEnvironment: J2EE (Java, JSP, JDBC, Multi-Threading), HTML, Oracle Web logic server, Eclipse, MySQL, JUnit.\n\nGolan Technologies \u2013 Newyork                                                \t\t          Jun\u201909 - Sep\u201911 \nRole: Java Developer\n\nGolan Technologies range from turnkey solutions to custom, client-driven solutions in a variety of product categories including website development and platform based applications, demand intelligence and business insight generation. Smart sites have the ability to provide a unified user experience and consistent messaging on websites across the globe, driving a favorable brand impression.\u00a0\n\nResponsibilities:\n\nInvolved in the analysis, design, implementation, and testing of the project.\nDeveloped UI using HTML, JavaScript, CSS and JSP for interactive cross browser functionality and complex user interface.\nImplemented the end-to-end functionality of the client requirement during the development phase.\nImplemented the functionality of mapping entities to the database using Hibernate.\nWritten SQL queries involved in the JDBC connection in accordance with the business logic.\nPerformed various levels of unit testing for the entire application using the test cases, which included preparation of detail documentation for the results.\nActively participated in client meetings and taking the inputs for the additional functionality.\nInvolved in fixing bugs and unit testing with test cases using JUnit.\n\nEnvironment: J2EE, Spring, Hibernate, JavaScript, CSS, Servlets, MySQL\n", "years_experience": 8, "score": 0.21349048189249364, "path": "C:\\Users\\admin\\resume\\AI-Resume-Ranker\\data\\uploads\\Candidate23_Hadoop_developer.docx"}, {"filename": "Candidate145_Project_Manager.docx", "text": "Candidate 145 \t\t\t\t\t\t         candidate14577@gmail.com 925-349 8018\nSummary\nOver 16 years of Project management and Business Data Analysis, securities, Banking experience, with emphasis on operational planning/implementation and data systems transitioning. Experienced in leading a project team, streamlining policies and procedures, designing training modules/documentation, and creating/monitoring performance metrics.\n\t\nHighlights\nOver 16 years of experience in Project management, Business / Data Analytics and Business Intelligence, Banking & Securities, Data Warehouse, Informatica, Business Objects, PMO, Business Improvement, Business Process Management, Consulting, IT Infrastructure Audit Management, DB Security and Technical Support. \nExcellent skills in client interfacing, requirement gathering, user support, quality assurance, problem solving, and documentation. \nFacilitate the day-to-day coordination of people, process, and technologies while ensuring business partner requirements are met.\nOversaw technical aspects of survey studies independently, including data analysis, programming, data management (including data archiving), and graphic presentation of findings for publications, reports and presentations\nPerformed data analyses relevant to demonstrating the validity and reliability of assessment tools designed to measure workplace diversity and those designed to measure the quality of diversity initiatives.\nContacts prospective and current bank (internal)customers to solicit new business to meet specific goals in order to expand banking services.\nMaintains a working knowledge of bank goals, policy and procedural expertise of products and services.\nEnsures all documents are completed in accordance with established policies and procedures, proper records are maintained accurately and information is entered on appropriate systems and routed to appropriate departments. Achieve compliance certification and use knowledge of compliance/CRA regulations in day to day activities.\nWorks independently and partners with application program managers/directors, stakeholders and system level subject matter experts to drive the work of the project team for large or highly integrated projects and programs.\nDemonstrates excellent management and leadership qualities with and across the company, as well as with corporate business partners Go-to person on project related issues\nHands on experience in various models such as Waterfall model, Agile model and Incremental model and performed GAP analysis to identify problems and inconsistencies. \nStrong domain/ functional knowledge of the Telecommunication platforms and protocols and have outstanding business communication skills. \nStrong knowledge of Project management skills such as time estimation, task identification, risk analysis and scope management and resource management. \nProject Manager with Knowledge and experience in Scrum/ PMBOK Methodologies\nStrong Client Relationship Management, People Management, Project Reviews, Communication, Status/Dashboard & Metrics Reporting, Project Planning and Tracking, Onsite-Offshore co-ordination, Effort Estimation.\nIndustry experience includes Banking, Financial, Retail and Manufacturing \nExperienced in working on Proposals, resource planning, budget planning, Kickoff new projects, SOW.\nSuccessfully managed complex projects with global implementation, and rapidly evolving requirements.\nHaving rich experience in translating Business requirements to understandable IT systems requirements and Implementing CMM Methods & Procedures across the organization.\n\nTechnical Skills\n\nCore Management Competencies\n\nData Analysis\t\t\tProject Management & Tracking \tBudgeting& Planning\nCost & Resource Estimates\t\tAgile & Waterfall Principles\t\tProject Risk & Scope\nProject & Delivery Methodologies\tChange Control Management\t        \tDelivery Management\nClient Management\t\t\tConflict Resolution\t\t\tQuality Management\n      Product Life Cycle Management \n\nEducation\nMasters Diploma in Business Administration 2004\nBachelor of Corporate Secretary ship, 1997\nGNX Program in 2000\nOracle Development \nE-commerce from Software Solution Integrated Solutions Limited. \nETL, Business Objects and Datawarehouse from Advance Technology Solutions\nCompleted PMP training and received 35 PDU\u2019s.\n\nKey Achievements\nPrepared the single golden source for IT Transformation which provides visibility for the business and the project team.\nRe-engineered the inventory and master tracker for IT Transformation Management team and developed metrics.\nResponsible building and developing SSIS Packages for Capacity Management data warehouse and implemented the same. Build custom reports for the business.                     \nResponsible for assisting and implementing security features and audit queries with in Teradata for the clients as per the business requirements.\n\nProfessional Experience\n\nFord Direct, Dearborn, MI\t\t\t\t\t\t\t\t\t  July 2017- Till Date\nRole:\t\t\t\t\t\t\t\t\t\t\tProject Manager/Data Analyst\n\nResponsibilities:\nResponsible for Collaborating with Ford Direct Business, Technology, Service Providers and Partners, Ford IT and\nCo-ordinate with Business teams to prepare an integrated project plan and execute it on time and budget.\nProject Management of digital applications within the Ford Marketing and Sales Digital space.\nAs a Project Manager collaborated with technology platform and business team.\nFunction as a owners to design, validate, oversee, and lead technology solutions.\nEngagement in Ford IT PMO processes for ensuring proper principles and communication.\nGathering and documentation of business and technical requirements.\nImplementation and support for the OIP, BI and Analytics systems and supporting integrations and Business areas.\nResponsible for implementation and rollout of Repair Order, EDD Web analytics, Leads and assigned projects.\nCoordinate system and application configuration and management tasks. \nCoordinate integration services, EDD product updates, change requests and Tier-3 support.\nUnderstanding the enhancement by constant interaction with the onsite team and doing a technical analysis on the enhancement to be done.\nCo-ordinated the OIP and cloudera upgrades to the latest version.\nValidate user stories/features/initiatives for system testing, report preparation, defect recording, and defect tracking.\nFacilitate recurring status meetings with Ford business, TDI, and other vendors working in Ford Digital space.\nWorked closely with internal or external project managers.\nIdentify and monitor project risks and communicate those risks on regular basis to project Leadership team.\n\nEnvironment: MS Project, MS Visio, Windows 2012 R2, SQL Server 2008 R2, MS Office, Net Suite, Bigdata, Jira, Release Management, Maria DB, Impala.\nDomain:  Automotive. Data warehouse, EDD and IT Infrastructure.\n\nCovisint, Southfield, MI \t\t\t\t\t\t\t\t\tMar 2016 \u2013 June 2017\nRole:\t\t\t\t\t\t\t\t\t\t\t\t          Project Manager\n\nResponsibilities:\nExtensively experience on implementing solutions using micro services, event driven design, NoSQL databases, data migrations, system migrations, cloud foundry, Aws and deep knowledge on identity and IoT domain.\nCreating and maintaining telematics business models for both user and org.\nResponsible for the up-time and availability of Client\u00a0Connected Services telematics solution and its supporting applications.\nCoordinate integration services, product updates, change requests and Tier-3 support.\nUnderstanding the enhancement by constant interaction with the onsite team and doing a technical analysis on the enhancement to be done.\nPossess and use strong project management skills and leadership abilities to deliver information technology solutions projects based on client's platform. \nImplemented agile scrum methodologies, from understanding user stories to story point estimation to done status.\nSince this was a scaled agile project, planned user stories, keeping in mind the different modules in the suite. Monitored continuous integration of the module with rest of the suite.\nWorked on software products on a cloud platform using state of the art cloud technologies, for the Covisint Identity Management Solutions / IOT. \nIdentity and Access / IOT Project Manager is responsible for managing the delivery of Covisint Identity Management solution as part of a global implementation for a Fortune 100 company.\nEstablish a configuration management library for the project and ensure all project documents are effectively managed within the library.\nProvide timely response to address server and client-server application performance and/or availability issues.\nLead, coordinate and participate in process improvements as they relate to IDM infrastructure and system\u00a0\nResearched on products and created business cases to present the engineering group when initiating new product development\nWorked with the marketing team to create promotions to drive incremental sales\nTrack various parts through stages of Product Life Cycle to ensure they priced competitively and suggest stocking levels \nTrack and report the financial status of the project regularly to the key stakeholders.\nSupport the design of end-to-end architecture solutions, collaborate on UX research and design\nManaging mobile solution delivery through all its phases, including Solution Design, Planning, Build and Test, Deployment and transition to Maintenance\nLeading high functioning technical teams including mobile solution architects, designers and developers to deliver mobile solutions for our clients\nWorking with key stakeholders to prepare a Project Schedule, overall scope, deliverables, organization, high-level schedule, and associated project management procedures for the project.\nPro-actively resolve project issues and solve problems throughout the project to achieve expected results.\nConsistently apply client's project management methods and contribute experiences and knowledge to continuously improve client's project management methods.\nCoach, mentor, develop and lead a best-in-class development team capable of delivering excellent results through agile iterative development methodologies to solving complex technical and business challenges in the area of connected Services.\nEnvironment: MS Project, MS Visio, Windows 2012 R2, Windows 2008 R2, SQL Server 2008 R2, MS Office, Net Suite, Jira, Release Management, Maria DB, Mobile \nDomain:  AWS, IT Infrastructure. Release Management, IDM, IOT and Auto IDM.\n\nPWC Tampa, FL \t\t\t\t\t\t\t\t\t\tOct 2015 \u2013 Feb 2016\t\nRole: \t\t\t\t\t\t\t\t\t\t                                  Project Manager Responsibilities:\nAs a business data analyst / project manager had good interpersonal skills and could deal with all kinds of people; for instance, from a foreman to a senior manager.\nAnalyzed business partner's operations to understand their strengths and weaknesses and determine opportunities to automate processes and functions.\nMaintained the data integrity during extraction, manipulation, processing, analysis and storage.\nBuilt data input and designed data collection screens \u2013 Managed database design and maintenance, administration and security for the company.\nMap the current set of business processes and how they interact systemically with external stakeholders.\nIdentify those critical business processes areas where process redesign could have the impact.\nCreate and execute a Corrective Action Plan, implementation plan that closes the performance gap specifically by addressing how the redesigned organizational and process changes will be introduced to the organization.\nMinimizes conflict and maximizes the chance it will be implemented successfully and not rejected by the organization and its members.\nDocument business processes using customized Business Process Modeling Notation in MS Visio and/or enterprise architectural tools\n\u00a0Research & recommend best practices to streamline, simplify, and increase compliance of the business process; analyze the root cause of risks or issues and provide solutions\nResponsible for the management of small, medium and large infrastructure, Advisory, Tax and Assurance projects.\nDeveloped strategic relationships with PwC IT team and business users.\nDevelop quarterly roadmaps and oversee the product design and development stages.\nSupply data and user-feedback to the technical team of software developers and experienced architecture team to design, develop and validate core features of the e-marketplace.\nInteract and engage with the customer segments on regular basis to identify and test traction channels \nUpgraded the SCCM Servers from old version to the new one SCCM 2012 Sp1 R2 Cu1 across various regions (US , UK, ME, CRB and BZL).\nUpgraded the HP ALM to the latest version 12.5 along with Agile Module and integrated the TFS 2015 with the same.\nAs a PM for GHRS US TAX Pharma and Analytics Reporting moved the scripts and provide the automation approach to PWC for the TAX Pharma and Analytics Reporting.\nDrove the strategic vision, architectural design and creation of a centralized data warehouse. Responsible for the scope, plan, budget, staffing requirements, server selection, software selection, database designs, capacity planning and security levels. Successfully delivered the corporate data warehouse on time and on budget.\nFacilitate scrum ceremonies (grooming, sprint planning, retrospe to communicate confer with the various people involved in the project both offshore and onsite and ensured that each finish the task assigned to him on time.\nComprehensive project management of new business application initiatives, performing requirements, gathering resource management, gap analysis, implementation configuration, scope control, testing according to project methodology\nManaged and maintain project information, including feature definition and scope, and epic and scrum planning.\nDrive efficiency and operational improvement through business process definition, system alignment, and optimization of standard business application functionality.\nInstructed and modeled core agile principles of collaboration, prioritization, team accountability and visibility; ensured consistent application of scrum methodologies across the enterprise.\nEnvironment: MS Project, MS Visio, Windows 2012 R2, Windows 2008 R2, SQL Server 2008 R2, MS Office, HP SM, HP PPM, DW, SQL.\nDomain:  Banking and\u00a0financial services, Securities, IT Audit  and IT Infrastructure.\n\nCitibank Tampa, FL\t\t\t\t\t\t\t\t\t\tApr 2015 \u2013 Sep 2015\nRole:\t\t\t\t\t\t\t\t\t                                               Project Manager\nResponsibilities:\nServes as the system and process requirements interpreter between developers and Enterprise Service Delivery User Community.\nConducts meetings with users to identify requirement needs and develops detailed user stories with applicable acceptance criteria\nCreates and manage approved 2-3 month backlog of clearly defined and prioritized user stories\nGains approval of user stories and Functional requirements documents (FRDs) by users, Development teams and Business Architect\nFocal point for making sound decisions related to data collection, data analysis, data security, methodologies and designs.\nMaintained the data integrity during extraction, manipulation, processing, analysis and storage.\nBuilt data input and designed data collection screens \u2013 Managed database design and maintenance, administration and security for the company.\nDatabase Design and Schema, Interpreting, using complex logical data and object models to guide technical design decisions and overall business application strategy.\nWorked with Managing Principal and others to scope and plan execution of complex Big Data and Analytics projects that leverage advanced technologies and analytics methodologies\nManaged day-to-day tracking and execution of project tasks - this is heavily based in JIRA and involves working with data engineers, systems engineers, and data scientists to write, assign, prioritize, update, and monitor tickets\nManaged day-to-day tracking of project costs, primarily in the form of hours worked - this is heavily based in our time-keeping system Harvest and involved working with data engineers, systems engineers, and data scientists to ensure that hours are accurately tracked in the right projects and tasks to support downstream reporting requirements\nImplemented agile scrum methodologies, from understanding user stories to story point estimation to done status.\nSince this was a scaled agile project, planned user stories, keeping in mind the different modules in the suite. Monitored continuous integration of the module with rest of the suite.\nAnalyzed massive and highly complex data sets, performing ad-hoc analysis and data manipulation.\nWrote reports using BO reporting system to extract data for analysis using filters based on the analysis.\nWork with business community to document functional test scenarios, test plans and end user acceptance testing criteria. \nParticipate in technical design sessions, working with technical resources, to provide insight during solution development.\nProvide ad hoc data queries or reports to the business for analysis using TOAD, Ab initio or other query tools\nExperience in co-coordinating with business and IT across all phases of software development life cycle.\nProject Architecture and Analysis of new requirements for application patches or upgrades to determine the impact to business and integrated systems.\nAs a business data analyst looking for an opportunity to make a difference by bringing my enthusiasm and expertise to the forefront of a leading company\u2019s business analysis and business decisions.\nIdentify gaps between the current deployment of applications and future requirements that have evolved due to organizational growth, changes, or strategy. \nEnvironment: MS Project, MS Visio, Windows 2012 R2, Bigdata, Windows 2008 R2, SQL Server 2008 R2, MS Office, HP SM, HP PPM, Ab initio, Toad, Netezza, Service Now, Jira\nDomain:  Banking and\u00a0financial services, Securities\n\n\n\n\n\nNational Grid Syracuse, NY\t\t\t\t\t\t\t\t             Nov 2014 - Mar 2015\nRole: \t\t\t\t\t\t\t\t\t\t\t\t        Project Manager\nResponsibilities:\nProject Planning, Execution, Monitor and Control all management plans to meet program/ project objectives\nConduct project Kick-off meetings, project review meetings on project plan, milestones, deliverables and Lessons learned and Project closing.\nProject Scoping, Estimating, Scheduling & Costing Plan budgetary forecast and resource forecast for the projects. Work with minimal direction to execute the project life cycle for complex projects dealing with all components of operations/ infrastructure.\nDirect weekly cross-functional team meetings as part of the forecast, inventory, and sales operations continuous improvement process\nReduced overall stocking locations by more than 10% by redesigning the strategic sourcing network\nManaging On-site and offshore teams to work together to meet the project objectives. Acted as Liaison (point of contact) with the internal customer\u2019s & offshore team\nAbility to work with different levels of management throughout an organization, excellent customer focus, and ability to manage multiple projects simultaneously \nDay-to-day activities of projects and staff; communicate with project teams to ensure project deliverables are on schedule and within cost parameters.\nSuggest recommendations to management about schedules, prioritization and resource allocation with input from team members\nExperienced in collaborating with developers and subject matter experts to build the technical vision and analysis trade-offs.\nFinance management including finance forecast and managing accruals & actual, work packs (Sow) to vendors, invoice receipt & approval\nManaging business users by working closely to ensure the project meets business needs and Identifying user training needs and devising and managing user training programs within the defined budget. Definition and management of the User Acceptance Testing program.\nHave good knowledge and experience in Project Management, EDI, ERP systems and delivery of complex technical IT projects and services.\nEnvironment: MS Project, MS Visio, Windows 2008 R2, SQL Server 2008 R2, MS Office, HP SM, HP PPM\nDomain:  Energy and Utilities. \n\nBank of New York Mellon (Chennai - IND/ Pittsburgh, PA) \t\t\t\t\tOct 2011 - Oct2014\t\nRole: \t\t\t\t\t\t\t\t\t\t\t\t      Project Manager\nResponsibilities:\nPartner with Marketing Risk Sales and COE teams to develop integrated solutions to grow credit card penetration and incremental sales and net income for the company\nProvide strategic thought leadership and influence business leaders and client teams to implement marketing and product strategies based upon customer financial and data-driven insights\nDevelop business case presentations and action plans to influence for marketing campaigns including targeting recommendations test design cross-sell optimization\nGuide marketing analytics and strategy development for new product launches customer acquisition lifecycle and retention initiatives\nIn the role of TPM (Technology Project Manager), I was responsible for managing large scale, high risk, high visibility (IT projects) and new business initiatives from initiation to delivery. \nThis includes but not limited to understand customer requirements, budget, objectives, user expectations and a plan accordingly making sure project are delivered on time, within budget and within company IT standards.\nPerformed all major aspects of a project management like - project discovery, kickoffs, drafting and driving project plans, project sizing and forecasting, scope, time and budget management, risk identification, status reporting, closer etc. \nSupported critical CR implementation activities involving game planning, communication planning, status reporting and co-ordination.\n2+ years of experience supporting Time Sheet and Resource Management HP Project and Portfolio Management (HP PPM) modules.\nSuccessfully migrated more than 25 projects from Waterfall to Scrum\u00a0\nPerform the installation and configuration of SAP Business Objects XI 3.1/4.0 based upon SAP Best Practices; \nConfigure CMS cluster, deploy war files, and configure app servers for SAP Business Objects XI3.1/4.0 on Licensee*s Test environment;\nIntegrate SAP Business Objects XI 3.1 with Licensee\u2019s Active Directory/LDAP and implement single-sign-on;\nRoad map creation for migration, Pre-Upgrade/migration Best Practice, Post-Upgrade/Migration Best practice\nProven ability to implement SAP BI solutions aligned with business objectives, enabling clients to leverage their Business Intelligence investment. \nGathered and analyzed the requirement to replicate the ECC content in HANA using\u00a0data provisioning.\nAssisted SAP Basis team in installing HANA 1.0 and solely integrated it with Business Objects 4.0 and BODS4.0.\nEstablished the best modeling and recommended strategies for BOBJ environment and architecture for\u00a0SAP HANA\nInstalled\u00a0BOBJ 4.0\u00a0and\u00a0BODS 4.0\u00a0and configured SAP and Windows AD authentication for Business objects enterprise\nIntegrated BOBJ 4.0 and BODS 4.0 with SAP HANA1.0.\nMigrated HANA content from development, testing environment to Production environment using delivery units\nDeveloped Webi reports and dashboards for different operations and finance KPI'S like\u00a0Project planning, quality management etc.\nCreated Universes on top of\u00a0HANA calculation views\u00a0and developed the Webi reports and dashboards using\u00a0IDT\nManaged the initial proof of concept initiative that was successful in securing the funding to carry the project in to full production implementation. Produced a working prototype utilizing Oracle Warehouse Builder and select features of the 11G initial release. Presented the POC findings to sponsors and business community to garner acceptance and support.\nProject managed and coordinated the activities for both the business and technology communities during each phase. Developed Project Scope, project definition documents and overall project plan. Distributed and managed project deliverables amongst Bentley internal staff and contract resources, tracking and reporting activities to all project participants on a persistent basis.\nSupervised and participated in logical and physical data structures creation, determined and defined business rules for data scrubbing, transformation and data refresh frequencies.\nStructured and scheduled vendor reviews during reporting and ETL tool selection process. Arranged for software delivery, installation and subsequent IT/User community training of the  Business Objects reporting suites\nManaged overall vendor/customer accounts for a function/department, including effective budget management.\nAbility to develop detailed project plans, budgets and schedules based on input from the project team. Ensures all plans are current and are in alignment with stakeholder expectations.\nPerforms full range of standard professional level work that typically requires processing and interpreting, more complex, less clearly-defined issues. Identifies problems and possible solutions and takes appropriate action to resolve.\nVendor Manager responsible for the outsourced voicemail system SLAs and on-line reporting.\nReduced the number of major services interruptions (incidents) infrastructure and network related from twenty-four (24) per year in 2014 to one (1) for 2015.\nWhile conducting Root Cause Analysis (RCA) managed support team resources to identify, assign, track, and implement over one hundred (100) corrective and pro-active action items.\nMonitor infrastructure project portfolio to ensure timely updates and performance reporting process.\nImprove project management capabilities, knowledge, competence, and skills. Provide up-to-date portfolio-level status reporting to executive management.\nEnvironment: MS Project, MS Visio, Windows 2008 R2, SQL Server 2008 R2, Informatica, Business Objects XI R2 4.0 SAP HANA, MS Office, HP SM, HP PPM, Data warehouse.\nDomain:  Banking and\u00a0financial services, Securities, and Infrastructure.\n\nCharming Shoppe Inc. (Chennai - IND /Bensalem, PA) \t\t\t\t\tMar 2011 \u2013 Sep 2011\t\nRole\t\t\t\t\t\t\t\t\t\t\t\t         Project Manager\t\nResponsibilities:\nDevelop and manage strategic staffing model for Merchandise Master Data  providing succession planning, career pathing and insulating the business from turnover\nRegularly assesses the value of existing processes and makes recommendations to better the process. Identifies and incorporates project management best practices in to their work\nData output \u2013 Made data chart presentations and coded variables from original data, conducted statistical analysis as and when required and provided summaries of analysis.\nTrained data analysis beginners to improve overall efficiency of department.\nTechnical ability to identify complex risk issues, formulate and manage a sequential course of action that will allow the issue to be managed and addressed.\nAs a PM I was responsible for managing various projects within the retail department. These include managing Corporate and Stores Portfolio.\nProject/delivery management along with good Delivery management skills through proactive stakeholder\u2019s engagement/communication and the detailed tracking of delivery activities, timelines, issues and risks. \nManaging all the POS system of the CSI and forming business case, budgets and project managing a schedule of works.\nSDLC process on software product/applications Risks/Compliance process Quality Control/Assurance process.\nA progressive culture of continuous improvement for Merchandise Master Data leading to service level commitments, data accuracy and system leverage\nConducted research to collect and assemble data for databases \u2013 Was responsible for design/development of relational databases for collecting data.\nMaintained the data integrity during extraction, manipulation, processing, analysis and storage.\nBuilt data input and designed data collection screens \u2013 Managed database design and maintenance, administration and security for the company.\nDiscussed intelligence and information requirements with internal and external personnel.\nAble to anticipate the consequences of decisions and planned quality related events and performed quality assurance.\nEnvironment: MS Project, MS Visio, Windows 2008 R2, SQL Server 2008 R2, MS Office, HP SM.\nDomain:  Retail Management\n\nCitibank (Warren County, NJ)\t\t\t\t\t\t                 Mar 2009 \u2013 Feb 2011\nRole: \t\t\t\t\t\t\t\t\t\t\t      Module Lead /  Data Analyst\nResponsibilities:\nOversee security and user management, including users, groups, roles, privileges, and permissions\nData and Business Intelligence Analyst \u2013 Responsible for analyzing financial data and statistical risk analysis for LOB of the Bank.\nProvide first level production support for Capacity Management databases and portals. Monitor Capacity Management databases and portals to avoid and detect outages.\nCreated reports for the BI team using SQL Reporting and BO.\nWorked on Importing and exporting data from different databases like Sybase, Oracle, Teradata to MS SQL.\nTest current and new functionality of capacity web portal on daily basis. \nCheck, maintain, verify data files for timeliness, accuracy and quality using scripting and automated processes. \nVerify accuracy of capacity reports prior to distribution Update in-house and vendor capacity tools with new server information.\nParticipate in automation of monitoring SSIS environments\nParticipate in projects and proactively build relationships with Business Units to understand new requirements, facilitate design discussions, and ultimately implement a finalized solution.\nDevelop teamwork and leadership skills by working with offshore colleagues to ensure work activities transition efficiently between shifts.\nAs a database System Administrators\\Designers was the key senior technical advisors designing, programming, optimizing and maintaining database solutions.  \nProvided solution using large scale server-side systems with distributed processing\nAnalyzed massive and highly complex data sets, performing ad-hoc analysis and data manipulation.\nWrote reports using SAP BO reporting system to extract data for analysis using filters based on the analysis.\nWorked on complex information model, logical relationships, and the data structures that support different LOB.\nFollowed the Agile project management methodology for the delivery.\nIdentify infrastructure goals and project delivery clearly. Define all activities necessary to acquire project goals and objectives. \nEvaluate and determine plan variance from project performance. Collect and present performance information related to infrastructure projects. \nEnsured the quality and integrity of Capacity Management team tools and reporting. \nEnvironment: MS Project, MS Visio, Windows 2008 R2, SQL Server 2008 R2, SSIS, MS Office, HP SM, Data warehouse.\nDomain:  Banking and\u00a0financial services, Securities\n\nCharles Schwab \u2013 (San Francisco, CA) \t\t\t\t\t\tJan 2007 - Feb 2009\nRole:\t\t\t\t\t\t\t\t\t\t\t                          Module Lead \nResponsibilities:\nAs part of Production support, I have also worked as Informatica Administration, everything from installation, to repository maintenance, scheduling etc.\nOversee security and user management, including users, groups, roles, privileges, and permissions\nParticipate in projects and proactively build relationships with Business Units to understand new requirements, facilitate design discussions, and ultimately implement a finalized solution.\nPerformed database health checks and tuned the databases using Teradata Manager.\nUsed Teradata Administrator and Teradata Manager Tools for monitoring and control the system.\nCreating and modifying Multi loads for Informatica using UNIX and loading data in Data Warehousing.\nInterpret data from primary and secondary sources using statistical techniques and provide ongoing reports.\nCompile and validate data; reinforce and maintain compliance with corporate standards.\nWorking with managing leadership to prioritize business and information requirements.\nWorking as an On-Site Teradata Lead DBA, doing DBA activities that are Implementation of data and table-level security, setting up access rights and space rights for Teradata environment. Performance tuning, Monitoring and reporting Review system utilization by user.\nDevelop teamwork and leadership skills by working with offshore colleagues to ensure work activities transition efficiently between shifts.\nShow cased independence and initiative to prioritize heavy workload, to manage the expectations of customers and to meet communicated deadlines of both projects and operational tasks.\nUnderstands and documented business and application requirements to make design decisions that are both financially sound and result in stable systems that meet operational standards.\nAct as a role model and positive influence for colleagues in support of firm, practice, unit, and customer missions, objectives, goals, and values.\nSharing best practices, collaborating with Risk Management teams and Project Management to maximize transparency and influence program delivery, comply with existing Ethics and Data Security policies, standards and processes.\n\nEnvironment: MS Project, MS Visio, UNIX, Informatica, Business Object XI R2, Teradata Security, Bteq Scripts, Remedy, Integrated Data Warehouse.\nDomain:  Banking and\u00a0financial services, Securities, BI\n\nBritish Petroleum \t\t\t\t\t\t\t\tJun 2006 \u2013 Dec 2006\nRole:\t\t\t\t\t\t\t\t\t\t\t\t         Project Engineer\t\nResponsibilities:\nProduced complex 'ad-hoc' queries and reports requested by external and internal customers using Business Objects\nDesign and develop data extracts from source SQL databases to meet analytics and reporting request\nPartnered directly with internal and external customers to research and troubleshoot data questions and issues\nMonitor plan dates and meet individual deliverables as well as support other team members to ensure project success\nPerform the installation and configuration of SAP Business Objects XI 3.1/4.0 based upon SAP Best Practices; \nConfigure CMS cluster, deploy war files, and configure app servers for SAP Business Objects XI3.1/4.0 on Licensee*s Test environment;\nIntegrate SAP Business Objects XI 3.1 with Licensee\u2019s Active Directory/LDAP and implement single-sign-on;\nRoad map creation for migration, Pre-Upgrade/migration Best Practice, Post-Upgrade/Migration Best practice\nProven ability to implement SAP BI solutions aligned with business objectives, enabling clients to leverage their Business Intelligence investment. \nEnvironment: Business Object 6.5, Oracle, UNIX Remedy.\nDomain:  Energy and Utilities\n\nBellsouth / AT&T \t\t\t\t\t\t\t\tDec 2003 \u2013 May 2006\nRole:\t\t\t\t\t\t\t\t\t\t\t\t         Project Engineer\nResponsibilities:\nCapability of handling Networks, Creating User accounts, assigning rights and sharing permissions, managing profiles and policies, IP addressing.\nConducting daily/weekly/monthly operations conference calls with the clients to discuss and resolve ongoing operational/strategic issues and to maintain cordial relationship with the clients through frequent on-line interaction.\nComfortable with both live and remote troubleshooting situations\nEnvironment:  Windows 3.x to Windows Vista, Mac 7.x to Mac OSX, Multimedia\nDomain:  Technical Support, Telecom. ISP.\n\nFord Business Service Center \t\t\t\t\t\tJun 2001 \u2013 Nov 2003\nRole:\t\t\t\t\t\t\t\t\t\t\t\t                       Analyst\t\nResponsibilities:\nWorked for US clients of Ford Motor Company handling North American Payables.\nProcessed accounts payable and expense reports in accordance with established policies and procedures.\nPrepared checks by ensuring proper support is attached for review.\nReconciled monthly corporate statement to support documentation and managed to resolve any discrepancies on a timely basis.\nPrepared monthly entries to the general ledger and prepared corresponding account reconciliations and assisted in the monthly closing process.\nEnvironment: Mainframe ERP, MS Office. Six Sigma Green Belt\nDomain:  Banking and\u00a0financial services and Accounting.\n\nGE Capital International Services \t\t\t\tJan 1999 -  May 2001\nRole:\t\t\t\t\t\t\t\t\t\t\t\t                       Analyst\nResponsibilities:\nWorked for US Client of GE Capital International Services. \nEfficiently served as a liaison between the business and IT Business needs.\nAccountable for documentation of Functional requirements and handed over to Technical Architecture team.  Analyzed business operation\u2019s strengths and weaknesses.\nIdentified opportunities for automating processes and functions.\nUnderwent & completed the Green Belt training of quality.\nEnvironment: Mainframe ERP, MS Office, Six Sigma Green Belt.\nDomain:  Banking and ITES\n", "years_experience": 16, "score": 0.2041011493568263, "path": "C:\\Users\\admin\\resume\\AI-Resume-Ranker\\data\\uploads\\Candidate145_Project_Manager.docx"}, {"filename": "lifelink_1.docx", "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Background and Necessity for the Website \n Proposed Solution\n Purpose of the Document\n Scope of Project\n Constraints\nFunctional Requirements\nNon-Functional Requirements\n Interface Requirements\n Hardware\n Software\n Project Deliverables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Background and Necessity for the Website  \n\nThis ambulance Website is a significant healthcare innovation that leverages technology to address the critical requirement of efficient and timely emergency medical transportation. Here are some reasons why such a Website would be required: \n  \nPrompt Assistance:\n This Website will help individuals request for ambulance services promptly and conveniently. It will also help them keep track of all the necessary updates such as the type of ambulance, their individual costs, their availability, and so on.\n\nForge the Connection: \nThis Website will help patients and medical emergency services to work together for saving a life. It will provide users with a secure and reliable platform to book ambulance services during critical situations. \n\n\nSupport and Maintenance: \nConsidering the vitality of this service, the Website must be available to its users/patients 24/7. This information promotes responsible and holistic approach to improve the emergency standards.\n\u2013\n\nSearching, Sorting, and Filtering Capabilities: \nWith a wide range of ambulance options, users may have specific preferences as per their requirements. The Website's search, sort, and filter features allow users to find all the ambulances that match their criteria efficiently. This saves time and enhances the overall user experience by narrowing down options based on their preferences.\n\nCustomer Engagement and Loyalty:\nA well-designed Website can foster customer engagement and loyalty by offering the best and fastest ambulances at critical times. This engagement strengthens the relationship between the customer and emergency services, thereby leveraging technology to provide rapid, efficient, and life-saving assistance to individuals.\n\n\n\n\n\n\n\n\n\n2. Proposed Solution\n \n The proposed solution is a Website called 'Life Link' for ambulances. The Website should enhance the efficiency and effectiveness of medical emergency services where users can browse and view different ambulances based on their requirements. It should also provide categories for different types of ambulances, offer sorting \n\nand filtering options, and allow users to search for a specific ambulance. Additionally, detailed information for each ambulance such as cost and availability should be displayed.\n\t            \n\n\n\n\n        \n3. Purpose of the Document\t\n\nThe purpose of this document is to present a detailed description of the Website, Life Link, an online ambulance service through which users can view different types of ambulances available near them. This document explains the purpose and features of the Website, the interface of the Website, what the Website will do, and the constraints under which it must operate. This document is intended for both stakeholders and developers of the Website.\n\nStakeholders and developers of the portal can use this document.\nSample Sitemap (with examples)\n                                                      Landing Page\n\n  \n\n\nHard-coded values will be displayed since, there is no scope for database fetching in this Website.\n\n5. Scope of Project\n\n The scope of this project is to develop a responsive and visually appealing Web portal for the users. This portal allows users to seamlessly and quickly search for the best ambulance for their requirement in any situation. Key features will include real-time availability, cost comparisons, and user-friendly navigation. The goal is to ensure that users can find the right emergency medical transport with minimal effort and maximum efficiency. \n6. Constraints\n\nThe Web portal will not have any facility to store information on the server. Information can be fetched from JSON/TXT files and users can view the same being displayed. However, information cannot be written to the files from within the portal.\n\n\n7. Functional Requirements\n\n The portal will be designed as a Single-Page-Application (SPA) and a responsive Website with a set of pages and menus that represent choice of activities to be performed. The pages, menus, and other visual elements must be designed in a visually appealing manner with attractive fonts, colors, and animations wherever applicable. All of these should also be laid out in a responsive manner.\n \nFollowing are the functional requirements of the portal: \nHome page: \nThe Website should allow users to browse through the catalog and view individual ambulance listings.\n\nAbout Us Page: \nUsers should be able to view information about the company and creators of the site. The company information can include number of cities/regions served by them and best performing ambulances.\nImages Gallery:\nUsers should be able to view different ambulance images uploaded on the Website.\n\nSearch, Sort, and Filter menus:\nUsers should be able to search for different types of ambulances and sort/filter them as per their requirements. One can search according to the area/region, for example, user can type \u2018Chicago\u2019 and it should display the ambulances available in this particular region. Sort and Filter should display based on users requirement such as costs or type of vehicle he/she wants.\n\nAmbulance Type:\nThe ambulance type menu should display the type/kind of vehicle, size, and equipment along with its costs to the users. The menu can also include specialization of the ambulance, such as A/C or Non-A/C, ICU or ICCU, and so on.\n\nFor example, users can search based on price $12 so it should display the ambulances available for this cost range.\n\nFeedback:  \nThe Feedback option should enable users to provide their feedback about the ambulance Website through a feedback form.\nContact Us:  \nThe Contact Us field should display the contact information of the creators of the Website. An email id and Contact Number can be displayed here.\n \nSitemap: \nTo help users understand the flow of the Website, you will create a Sitemap and add it to the home page of your Website.\n  \t \nTechnical Considerations: \n\u2022 Use HTML5, CSS3, Figma Toolkit, Bootstrap, jQuery, and JavaScript to build the User Interface (UI). \n\u2022 Use either Angular or React JS to develop the application's frontend and add dynamic and responsive features along with SPA functionality. \n\u2022 Use JSON/TXT files to handle data retrieval.\n \u2022 Ensure the application is responsive and compatible with different screen sizes.\nTasks: \nDesign the UI for the LifeLink Website including the catalog display, searchbar ,sorting options, and eAmbulance information section\nCreate necessary components and services to display the Ambulance type and handle searching ,sorting, and filtering operations.\n  Implement the Website\u2019s required functionalities. \n Implement GPS functionality as applicable.\n Optionally, use REST APIs if you are well-versed with them.\n Test the Website's functionality including browsing, searching, and adding feedback. Deploy the Website to a local Web server such as XAMPP for testing purposes\n\n\t\n8.Non-Functional Requirements\n\nThere are several non-functional requirements that should be fulfilled by the Website. \n  \nThe Website should be: \nSafe to use: The Website should not result in any malicious downloads or unnecessary file downloads. \nAccessible: The Website should have clear and legible fonts, user-interface elements, and navigation elements. \nUser-friendly: The Website should be easy to navigate with clear and easy to understand elements. \nOperability: The Website should reliable and efficient. \nPerformance: The Website should demonstrate high value of performance through speed and throughput. In simple terms, the Website should have minimal load time and smooth page redirection. \nCapacity: The Website should support large number of concurrent users.\nAvailability: The Website should be available 24/7 with minimum downtime.  \nCompatibility: The Website should be compatible with latest browsers and devices.\n\n\n\n\n\n\n\n1.9  Project Deliverables\n\nYou will design and build the project and submit it along with a complete project report \nthat includes: \n* Problem Definition \n* Design Specifications \n* Diagrams such as flowcharts for various Activities, Data Flow Diagrams, and so on \n* Test Data Used in the Project \n* Project Installation Instructions (if any) \n \n1.9.1 Problem Definition\n\nA clear and concise statement of the problem the project aims to solve. For this project, the problem definition would focus on providing an efficient and user-friendly platform for users to browse, search, and filter ambulance services.\n\n\n1.9.2 Design Specification\n\nDetailed documentation of the design aspects of the project. This should cover the overall architecture of the website, including how different components such as UI elements, backend services, and data handling are designed. It should also include:\n\nUser Interface (UI) design, wireframes, or mockups.\nComponent breakdowns for frontend development (e.g., home page, search/filter functionality, feedback form, etc.).\n\n\n1.9.3 FlowChart Diagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.9.3 DataFlow Diagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.9.4 Test Data Used in the Project\n\nProvide the test cases and test data that were used to verify the functionality of the website. This should cover:\n\nSearch, filter, and sort functionalities.\nUI responsiveness across different devices.\nFeedback form submission and other user interactions.\n\n\n\n\n1.9.5 Project Installation Instructions (if any)\n\nDetailed instructions for installing and running the project on a local or remote server. If XAMPP or another web server is required, the instructions should include:\n\nHow to install necessary software (e.g., Node.js, XAMPP).\nHow to configure the project (e.g., downloading dependencies, configuring ports).\nHow to start the website on a local machine or server.\nAny additional environment setup (e.g., connecting to a backend data source or API, setting up JSON files).\n\n\n\n\n\n\n\n", "years_experience": 0, "score": 0.05121638122682487, "path": "C:\\Users\\admin\\resume\\AI-Resume-Ranker\\data\\uploads\\lifelink_1.docx"}, {"filename": "FurEver_Care.docx", "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Background and Necessity for the Website \n Proposed Solution\n Purpose of the Document\n Scope of Project\n Constraints\nFunctional Requirements\nNon-Functional Requirements\n Interface Requirements\n Hardware\n Software\n Project Deliverables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Background and Necessity for the Website  \n\nIn today's fast-paced world, pet owners face difficulties in organizing pet care activities such as feeding schedules, grooming routines, health monitoring, and product selection. Additionally, navigating different Websites for pet products such as food, toys, and grooming essentials can be inconvenient.\n\nThere is a growing requirement for a single, user-friendly platform that not only provides care guidance, but also lists recommended pet products  \n\nHere are some reasons why such a Website would be required:\n\n\u2663 Centralized Pet Management:\nTo help pet owners track pet profiles, medical records, and essential care routines in one place.\n\n\u2663 24/7 Access to Information:\nOffers convenient access to pet care details, vet appointments, and product recommendations anytime, anywhere.\n\n\u2663 Promotes Pet Wellness:\nProvides timely care tips, feeding advice, and health alerts to improve overall pet well-being.\n\n\u2663 Supports Adoption and Rescue:\nHelps animal shelters showcase adoptable pets and streamline adoption requests through an online platform.\n\u2663 Enables Product Discovery: \nOffers curated listings of pet food, grooming supplies, and toys making it easier for owners to shop.\n\u2663 Build a Pet-Loving Community:\n Encourages engagement through blogs, tips, and community posts helping users share experiences and learn. \n\u2663 Paperless & Eco-Friendly:\n Encourages sustainable, paper-free management of pet care and communication with service providers.\n\n\n\n2. Proposed Solution\n \n The proposed solution is a Website called 'FurEver Care' for Pet Care. The Website should enhance the efficiency and effectiveness of pet care services where users can manage pet profiles, view appointments, and access various petrelated resources. The system should support categories for pet owners, veterinarians, and shelters; enable users to manage pet medical history and provide sorting and filtering for services and products.\n Additionally, detailed information about each pet, upcoming vaccinations, grooming sessions, health records, and available pet products should be displayed. The platform should aim to simplify pet care management while promoting better health, timely services, and community engagement.\t            \n\n\n\n\n        \n\n\n\n\n\n\n\n\n3. Purpose of the Document\t\n\nThe purpose of this document is to present a detailed description of the Website \u2018FurEver Care\u2019 an online pet care platform through which users can manage pet profiles, view appointments with veterinarians or groomers, access pet health records, and explore pet-related products and services.\nThis document outlines the objectives and features of the Website, its user interfaces, the functions it is expected to perform, and the constraints under which it must operate. It is intended to serve as a reference for both the stakeholders and the developers involved in designing, building, and maintaining the Website.\nSample Sitemap (with examples)\n                                                      Landing Page\n\n\n\n\u2663 Upon selecting an option, the respective page should be displayed, where relevant information can be accepted by the user via a form. Based on the type of user appropriate menus should be displayed.\n\n\n\n4. Scope of Project\n\n The Website will offer a range of features aimed at improving the overall experience for pet owners, veterinarians, and animal shelters. It will include static pet profile and care sections that allow users to view and manage essential information about their pets. The platform will support multimedia features, enabling access to engaging content related to pet training, grooming, and general wellness. Users will also be able to explore static product listings for essential pet supplies such as food, toys, and grooming items. For shelters, the Website will showcase pets available for adoption, complete with filtering options based on type, age, breed, and location to enhance discoverability. For veterinarians, a dedicated dashboard will be provided, allowing them to view appointments, review pet medical histories, and view treatment records thus, streamlining veterinary services and improving care coordination.\n5. Constraints\n\nThe Web portal will not have any facility to store information on the server. Information can be fetched from JSON/TXT files and users can view the same being displayed, however, information cannot be written to the files from within the portal.\n\n\n6. Functional Requirements\n\n The portal will be designed as a Single-Page-Application (SPA) and responsive Website with a set of pages and menus that represent choice of activities to be performed. The pages, menus, and other visual elements must be designed in a visually appealing manner with attractive fonts, colors, and animations. All of these should also be laid out in a responsive manner.\n\nMenu and Web Page Functionality:\n \nFollowing are the functional requirements of the portal: \nHome page: \nThe home page should accept the first name from the user and display a personalized welcome message on other pages. At the top corner, the user's first name should be displayed for the entire duration that the portal is loaded. The home page must also accept category of users in the form of radio button selection. Based on selection, respective pages and menus will be displayed. Refer to the Sitemap section to see sample menus.\n2.For Pet Owner:\nCollect information of pets such as name, species, breed, age, and so on using a form.\n            \n        3.Pet Care Sections: \nPet Profile (Static) \u2013 Species, breed, age, vaccination info, and so on\nFeeding Guide \u2013 Charts for puppies, adults, cats, and so on\nGrooming Videos \u2013 Brushing, bathing, and trimming (embedded)\nHealth Tips Audio/video \u2013 Oral care, weight, and common conditions\nTraining Tips \u2013 Audio + text-based guides\n\nScrolling ticker with location (HTML5 Geolocation), time, and updates should be displayed.\n4. Pet Product Showcase:\nCategories:\nDog/Cat Food\nToys\nGrooming Essentials\nBedding and Apparel\nHealth Supplements\n\nEach product card includes:\nProduct name\n Image \n Description\n Price\nBuy Now button (nonfunctional)\n   Loaded via JSON \u2013 Use AngularJS/ReactJS or plain JS to load cards dynamically.\n\nAll this data can be sorted, filtered, or searched via text box.\n\n\n\t\n7.Non-Functional Requirements\n\nThere are several non-functional requirements that should be fulfilled by the Website.\n\n The Website should be:\n\n Safe to use: \nThe Website should not result in any malicious downloads or unnecessary file downloads.\n\nAccessible:\n The Website should have clear and legible fonts, user-interface elements, and navigation elements.\n User-friendly: \nThe Website should be easy to navigate with clear items and other elements and easy to understand.\nOperability: \nThe Website should operate in a reliably efficient manner. Performance: The Website should demonstrate high value of performance through speed and throughput. In simple terms, the Website should be fast to load and page redirection should be smooth. \n\nCapacity:\nThe Website should support large number of users. Availability: The Website should be available 24/7 with minimum downtime. \n\nCompatibility:\nThe Website should be compatible with latest browsers.\n\n\n8.  Interface Requirements\n\n8.1 Hardware\nIntel Core i5 Processor or\nhigher\n8 GB RAM or higher\nColor SVGA monitor\n500 GB Hard Disk space\nMouse\nKeyboard\n\n\n\n8.2 Software\nTechnologies to be used:\nIDE: Visual Studio Code, Coffee Cup, Notepad++, or any other HTML editor\nFrontend: HTML5, CSS3, Bootstrap (optional), JavaScript, Figma,Toolkit, jQuery, Angular/ReactJS, and XML\nData Store: JSON/TXT\n\n\n\n\n\n\n\n\n\n9. Project Deliverables\n\nYou will design and build the project and submit it along with a complete project report that includes:\nProblem Definition \nDesign specifications \nDiagrams such as flowcharts for various activities, Data Flow Diagrams, and so on \nSource Code \nTest Data Used in the Project \nProject Installation Instructions (if any)\n  Documentation is considered a very important part of the project.                                                              Ensure that documentation is complete and comprehensive. The consolidated project will be submitted as a zip file with a ReadMe.doc file listing assumptions (if any) made.\nSubmit a video clip demonstrating the working of the Website. Optionally, a live hosted URL can be supplied for the site. Over and above the given specifications, you can apply your creativity and logic to improve the portal.\nUser Interface (UI) design, wireframes, or mockups.\nComponent breakdowns for frontend development (e.g., home page, search/filter functionality, feedback form, etc.).\n\n\n\n\n\n\n\n\n\n\n\nHome Page:\n\n\n\nPet Owner Detail:\n\n\n\n\n\n\n\n\n\nPet Owner:\n\n\n\n\n\n\n\n\nPet Owner Products:\n\n\n\n\nPet Owner Emergency\n\n\n\n\nPet Owner Feedback\n\n\n\nPet Owner Contact Us\n\n\n\n\nAbout Us:\n\n\n", "years_experience": 0, "score": 0.02615034722998874, "path": "C:\\Users\\admin\\resume\\AI-Resume-Ranker\\data\\uploads\\FurEver_Care.docx"}, {"filename": "FurEver_Care_1.docx", "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Background and Necessity for the Website \n Proposed Solution\n Purpose of the Document\n Scope of Project\n Constraints\nFunctional Requirements\nNon-Functional Requirements\n Interface Requirements\n Hardware\n Software\n Project Deliverables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Background and Necessity for the Website  \n\nIn today's fast-paced world, pet owners face difficulties in organizing pet care activities such as feeding schedules, grooming routines, health monitoring, and product selection. Additionally, navigating different Websites for pet products such as food, toys, and grooming essentials can be inconvenient.\n\nThere is a growing requirement for a single, user-friendly platform that not only provides care guidance, but also lists recommended pet products  \n\nHere are some reasons why such a Website would be required:\n\n\u2663 Centralized Pet Management:\nTo help pet owners track pet profiles, medical records, and essential care routines in one place.\n\n\u2663 24/7 Access to Information:\nOffers convenient access to pet care details, vet appointments, and product recommendations anytime, anywhere.\n\n\u2663 Promotes Pet Wellness:\nProvides timely care tips, feeding advice, and health alerts to improve overall pet well-being.\n\n\u2663 Supports Adoption and Rescue:\nHelps animal shelters showcase adoptable pets and streamline adoption requests through an online platform.\n\u2663 Enables Product Discovery: \nOffers curated listings of pet food, grooming supplies, and toys making it easier for owners to shop.\n\u2663 Build a Pet-Loving Community:\n Encourages engagement through blogs, tips, and community posts helping users share experiences and learn. \n\u2663 Paperless & Eco-Friendly:\n Encourages sustainable, paper-free management of pet care and communication with service providers.\n\n\n\n2. Proposed Solution\n \n The proposed solution is a Website called 'FurEver Care' for Pet Care. The Website should enhance the efficiency and effectiveness of pet care services where users can manage pet profiles, view appointments, and access various petrelated resources. The system should support categories for pet owners, veterinarians, and shelters; enable users to manage pet medical history and provide sorting and filtering for services and products.\n Additionally, detailed information about each pet, upcoming vaccinations, grooming sessions, health records, and available pet products should be displayed. The platform should aim to simplify pet care management while promoting better health, timely services, and community engagement.\t            \n\n\n\n\n        \n\n\n\n\n\n\n\n\n3. Purpose of the Document\t\n\nThe purpose of this document is to present a detailed description of the Website \u2018FurEver Care\u2019 an online pet care platform through which users can manage pet profiles, view appointments with veterinarians or groomers, access pet health records, and explore pet-related products and services.\nThis document outlines the objectives and features of the Website, its user interfaces, the functions it is expected to perform, and the constraints under which it must operate. It is intended to serve as a reference for both the stakeholders and the developers involved in designing, building, and maintaining the Website.\nSample Sitemap (with examples)\n                                                      Landing Page\n\n\n\n\u2663 Upon selecting an option, the respective page should be displayed, where relevant information can be accepted by the user via a form. Based on the type of user appropriate menus should be displayed.\n\n\n\n4. Scope of Project\n\n The Website will offer a range of features aimed at improving the overall experience for pet owners, veterinarians, and animal shelters. It will include static pet profile and care sections that allow users to view and manage essential information about their pets. The platform will support multimedia features, enabling access to engaging content related to pet training, grooming, and general wellness. Users will also be able to explore static product listings for essential pet supplies such as food, toys, and grooming items. For shelters, the Website will showcase pets available for adoption, complete with filtering options based on type, age, breed, and location to enhance discoverability. For veterinarians, a dedicated dashboard will be provided, allowing them to view appointments, review pet medical histories, and view treatment records thus, streamlining veterinary services and improving care coordination.\n5. Constraints\n\nThe Web portal will not have any facility to store information on the server. Information can be fetched from JSON/TXT files and users can view the same being displayed, however, information cannot be written to the files from within the portal.\n\n\n6. Functional Requirements\n\n The portal will be designed as a Single-Page-Application (SPA) and responsive Website with a set of pages and menus that represent choice of activities to be performed. The pages, menus, and other visual elements must be designed in a visually appealing manner with attractive fonts, colors, and animations. All of these should also be laid out in a responsive manner.\n\nMenu and Web Page Functionality:\n \nFollowing are the functional requirements of the portal: \nHome page: \nThe home page should accept the first name from the user and display a personalized welcome message on other pages. At the top corner, the user's first name should be displayed for the entire duration that the portal is loaded. The home page must also accept category of users in the form of radio button selection. Based on selection, respective pages and menus will be displayed. Refer to the Sitemap section to see sample menus.\n2.For Pet Owner:\nCollect information of pets such as name, species, breed, age, and so on using a form.\n            \n        3.Pet Care Sections: \nPet Profile (Static) \u2013 Species, breed, age, vaccination info, and so on\nFeeding Guide \u2013 Charts for puppies, adults, cats, and so on\nGrooming Videos \u2013 Brushing, bathing, and trimming (embedded)\nHealth Tips Audio/video \u2013 Oral care, weight, and common conditions\nTraining Tips \u2013 Audio + text-based guides\n\nScrolling ticker with location (HTML5 Geolocation), time, and updates should be displayed.\n4. Pet Product Showcase:\nCategories:\nDog/Cat Food\nToys\nGrooming Essentials\nBedding and Apparel\nHealth Supplements\n\nEach product card includes:\nProduct name\n Image \n Description\n Price\nBuy Now button (nonfunctional)\n   Loaded via JSON \u2013 Use AngularJS/ReactJS or plain JS to load cards dynamically.\n\nAll this data can be sorted, filtered, or searched via text box.\n\n\n\t\n7.Non-Functional Requirements\n\nThere are several non-functional requirements that should be fulfilled by the Website.\n\n The Website should be:\n\n Safe to use: \nThe Website should not result in any malicious downloads or unnecessary file downloads.\n\nAccessible:\n The Website should have clear and legible fonts, user-interface elements, and navigation elements.\n User-friendly: \nThe Website should be easy to navigate with clear items and other elements and easy to understand.\nOperability: \nThe Website should operate in a reliably efficient manner. Performance: The Website should demonstrate high value of performance through speed and throughput. In simple terms, the Website should be fast to load and page redirection should be smooth. \n\nCapacity:\nThe Website should support large number of users. Availability: The Website should be available 24/7 with minimum downtime. \n\nCompatibility:\nThe Website should be compatible with latest browsers.\n\n\n8.  Interface Requirements\n\n8.1 Hardware\nIntel Core i5 Processor or\nhigher\n8 GB RAM or higher\nColor SVGA monitor\n500 GB Hard Disk space\nMouse\nKeyboard\n\n\n\n8.2 Software\nTechnologies to be used:\nIDE: Visual Studio Code, Coffee Cup, Notepad++, or any other HTML editor\nFrontend: HTML5, CSS3, Bootstrap (optional), JavaScript, Figma,Toolkit, jQuery, Angular/ReactJS, and XML\nData Store: JSON/TXT\n\n\n\n\n\n\n\n\n\n9. Project Deliverables\n\nYou will design and build the project and submit it along with a complete project report that includes:\nProblem Definition \nDesign specifications \nDiagrams such as flowcharts for various activities, Data Flow Diagrams, and so on \nSource Code \nTest Data Used in the Project \nProject Installation Instructions (if any)\n  Documentation is considered a very important part of the project.                                                              Ensure that documentation is complete and comprehensive. The consolidated project will be submitted as a zip file with a ReadMe.doc file listing assumptions (if any) made.\nSubmit a video clip demonstrating the working of the Website. Optionally, a live hosted URL can be supplied for the site. Over and above the given specifications, you can apply your creativity and logic to improve the portal.\nUser Interface (UI) design, wireframes, or mockups.\nComponent breakdowns for frontend development (e.g., home page, search/filter functionality, feedback form, etc.).\n\n\n\n\n\n\n\n\n\n\n\nHome Page:\n\n\n\nPet Owner Detail:\n\n\n\n\n\n\n\n\n\nPet Owner:\n\n\n\n\n\n\n\n\nPet Owner Products:\n\n\n\n\nPet Owner Emergency\n\n\n\n\nPet Owner Feedback\n\n\n\nPet Owner Contact Us\n\n\n\n\nAbout Us:\n\n\n", "years_experience": 0, "score": 0.02615034722998874, "path": "C:\\Users\\admin\\resume\\AI-Resume-Ranker\\data\\uploads\\FurEver_Care_1.docx"}, {"filename": "lifelink.docx", "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Background and Necessity for the Website \n Proposed Solution\n Purpose of the Document\n Scope of Project\n Constraints\nFunctional Requirements\nNon-Functional Requirements\n Interface Requirements\n Hardware\n Software\n Project Deliverables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Background and Necessity for the Website  \n\nIn today's fast-paced world, pet owners face difficulties in organizing pet care activities such as feeding schedules, grooming routines, health monitoring, and product selection. Additionally, navigating different Websites for pet products such as food, toys, and grooming essentials can be inconvenient.\n\nThere is a growing requirement for a single, user-friendly platform that not only provides care guidance, but also lists recommended pet products  \n\nHere are some reasons why such a Website would be required:\n\n\u2663 Centralized Pet Management:\nTo help pet owners track pet profiles, medical records, and essential care routines in one place.\n\n\u2663 24/7 Access to Information:\nOffers convenient access to pet care details, vet appointments, and product recommendations anytime, anywhere.\n\n\u2663 Promotes Pet Wellness:\nProvides timely care tips, feeding advice, and health alerts to improve overall pet well-being.\n\n\u2663 Supports Adoption and Rescue:\nHelps animal shelters showcase adoptable pets and streamline adoption requests through an online platform.\n\u2663 Enables Product Discovery: \nOffers curated listings of pet food, grooming supplies, and toys making it easier for owners to shop.\n\u2663 Build a Pet-Loving Community:\n Encourages engagement through blogs, tips, and community posts helping users share experiences and learn. \n\u2663 Paperless & Eco-Friendly:\n Encourages sustainable, paper-free management of pet care and communication with service providers.\n\n\n\n2. Proposed Solution\n \n The proposed solution is a Website called 'FurEver Care' for Pet Care. The Website should enhance the efficiency and effectiveness of pet care services where users can manage pet profiles, view appointments, and access various petrelated resources. The system should support categories for pet owners, veterinarians, and shelters; enable users to manage pet medical history and provide sorting and filtering for services and products.\n Additionally, detailed information about each pet, upcoming vaccinations, grooming sessions, health records, and available pet products should be displayed. The platform should aim to simplify pet care management while promoting better health, timely services, and community engagement.\t            \n\n\n\n\n        \n\n\n\n\n\n\n\n\n3. Purpose of the Document\t\n\nThe purpose of this document is to present a detailed description of the Website \u2018FurEver Care\u2019 an online pet care platform through which users can manage pet profiles, view appointments with veterinarians or groomers, access pet health records, and explore pet-related products and services.\nThis document outlines the objectives and features of the Website, its user interfaces, the functions it is expected to perform, and the constraints under which it must operate. It is intended to serve as a reference for both the stakeholders and the developers involved in designing, building, and maintaining the Website.\nSample Sitemap (with examples)\n                                                      Landing Page\n\n\n\n\u2663 Upon selecting an option, the respective page should be displayed, where relevant information can be accepted by the user via a form. Based on the type of user appropriate menus should be displayed.\n\n\n\n4. Scope of Project\n\n The Website will offer a range of features aimed at improving the overall experience for pet owners, veterinarians, and animal shelters. It will include static pet profile and care sections that allow users to view and manage essential information about their pets. The platform will support multimedia features, enabling access to engaging content related to pet training, grooming, and general wellness. Users will also be able to explore static product listings for essential pet supplies such as food, toys, and grooming items. For shelters, the Website will showcase pets available for adoption, complete with filtering options based on type, age, breed, and location to enhance discoverability. For veterinarians, a dedicated dashboard will be provided, allowing them to view appointments, review pet medical histories, and view treatment records thus, streamlining veterinary services and improving care coordination.\n5. Constraints\n\nThe Web portal will not have any facility to store information on the server. Information can be fetched from JSON/TXT files and users can view the same being displayed, however, information cannot be written to the files from within the portal.\n\n\n6. Functional Requirements\n\n The portal will be designed as a Single-Page-Application (SPA) and responsive Website with a set of pages and menus that represent choice of activities to be performed. The pages, menus, and other visual elements must be designed in a visually appealing manner with attractive fonts, colors, and animations. All of these should also be laid out in a responsive manner.\n\nMenu and Web Page Functionality:\n \nFollowing are the functional requirements of the portal: \nHome page: \nThe home page should accept the first name from the user and display a personalized welcome message on other pages. At the top corner, the user's first name should be displayed for the entire duration that the portal is loaded. The home page must also accept category of users in the form of radio button selection. Based on selection, respective pages and menus will be displayed. Refer to the Sitemap section to see sample menus.\n2.For Pet Owner:\nCollect information of pets such as name, species, breed, age, and so on using a form.\n            \n        3.Pet Care Sections: \nPet Profile (Static) \u2013 Species, breed, age, vaccination info, and so on\nFeeding Guide \u2013 Charts for puppies, adults, cats, and so on\nGrooming Videos \u2013 Brushing, bathing, and trimming (embedded)\nHealth Tips Audio/video \u2013 Oral care, weight, and common conditions\nTraining Tips \u2013 Audio + text-based guides\n\nScrolling ticker with location (HTML5 Geolocation), time, and updates should be displayed.\n4. Pet Product Showcase:\nCategories:\nDog/Cat Food\nToys\nGrooming Essentials\nBedding and Apparel\nHealth Supplements\n\nEach product card includes:\nProduct name\n Image \n Description\n Price\nBuy Now button (nonfunctional)\n   Loaded via JSON \u2013 Use AngularJS/ReactJS or plain JS to load cards dynamically.\n\nAll this data can be sorted, filtered, or searched via text box.\n\n\n\t\n7.Non-Functional Requirements\n\nThere are several non-functional requirements that should be fulfilled by the Website.\n\n The Website should be:\n\n Safe to use: \nThe Website should not result in any malicious downloads or unnecessary file downloads.\n\nAccessible:\n The Website should have clear and legible fonts, user-interface elements, and navigation elements.\n User-friendly: \nThe Website should be easy to navigate with clear items and other elements and easy to understand.\nOperability: \nThe Website should operate in a reliably efficient manner. Performance: The Website should demonstrate high value of performance through speed and throughput. In simple terms, the Website should be fast to load and page redirection should be smooth. \n\nCapacity:\nThe Website should support large number of users. Availability: The Website should be available 24/7 with minimum downtime. \n\nCompatibility:\nThe Website should be compatible with latest browsers.\n\n\n8.  Interface Requirements\n\n8.1 Hardware\nIntel Core i5 Processor or\nhigher\n8 GB RAM or higher\nColor SVGA monitor\n500 GB Hard Disk space\nMouse\nKeyboard\n\n\n\n8.2 Software\nTechnologies to be used:\nIDE: Visual Studio Code, Coffee Cup, Notepad++, or any other HTML editor\nFrontend: HTML5, CSS3, Bootstrap (optional), JavaScript, Figma,Toolkit, jQuery, Angular/ReactJS, and XML\nData Store: JSON/TXT\n\n\n\n\n\n\n\n\n\n9. Project Deliverables\n\nYou will design and build the project and submit it along with a complete project report that includes:\nProblem Definition \nDesign specifications \nDiagrams such as flowcharts for various activities, Data Flow Diagrams, and so on \nSource Code \nTest Data Used in the Project \nProject Installation Instructions (if any)\n  Documentation is considered a very important part of the project.                                                              Ensure that documentation is complete and comprehensive. The consolidated project will be submitted as a zip file with a ReadMe.doc file listing assumptions (if any) made.\nSubmit a video clip demonstrating the working of the Website. Optionally, a live hosted URL can be supplied for the site. Over and above the given specifications, you can apply your creativity and logic to improve the portal.\nUser Interface (UI) design, wireframes, or mockups.\nComponent breakdowns for frontend development (e.g., home page, search/filter functionality, feedback form, etc.).\n\n\n\n\n\n\n\n\n\n\n\nHome Page:\n\n\n\nPet Owner Detail:\n\n\n\n\n\n\n\n\n\nPet Owner:\n\n\n\n\n\n\n\n\nPet Owner Products:\n\n\n\n\nPet Owner Emergency\n\n\n\n\nPet Owner Feedback\n\n\n\nPet Owner Contact Us\n\n\n\n\nAbout Us:\n\n\n", "years_experience": 0, "score": 0.02615034722998874, "path": "C:\\Users\\admin\\resume\\AI-Resume-Ranker\\data\\uploads\\lifelink.docx"}]